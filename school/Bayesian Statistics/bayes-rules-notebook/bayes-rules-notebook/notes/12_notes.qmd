---
title: "12: Poisson & Negative Binomial Regression"
editor_options: 
  chunk_output_type: console
---

```{r setup, warning=FALSE, message=FALSE}

# Load packages
library(bayesrules)
library(rstanarm)
library(bayesplot)
library(tidyverse)
library(tidybayes)
library(broom.mixed)

colors <- c("#7400CC", "#CC0AA4", "#3ACC14", "#0E0ACC", "#CCAC14", 
            "#CC5514", "#0ACCC5")

# Load data
data(equality_index)
equality <- equality_index

```

```{r}

ggplot(equality, aes(x = laws)) + 
  geom_histogram(color = "white", breaks = seq(0, 160, by = 10))

# Identify the outlier
equality %>% 
  filter(laws == max(laws))

# Remove the outlier
equality <- equality %>% 
  filter(state != "california")

ggplot(equality, aes(y = laws, x = percent_urban, color = historical)) + 
  geom_point() +
  scale_color_manual(values = colors)

```

```{r, cache=TRUE}

# Simulate the Normal model
equality_normal_sim <- stan_glm(laws ~ percent_urban + historical, 
                                data = equality, 
                                family = gaussian,
                                prior_intercept = normal(7, 1.5),
                                prior = normal(0, 2.5, autoscale = TRUE),
                                prior_aux = exponential(1, autoscale = TRUE),
                                chains = 4, iter = 5000*2, seed = 84735)

# Posterior predictive check
pp_check(equality_normal_sim, plotfun = "hist", nreps = 5) + 
  geom_vline(xintercept = 0) + 
  xlab("laws")

```

# 12.1 Building the Poisson regression model

## 12.1.2 Specifying the priors

```{r, cache=TRUE}

equality_model_prior <- stan_glm(laws ~ percent_urban + historical, 
                                 data = equality, 
                                 family = poisson,
                                 prior_intercept = normal(2, 0.5),
                                 prior = normal(0, 2.5, autoscale = TRUE), 
                                 chains = 4, iter = 5000*2, seed = 84735, 
                                 prior_PD = TRUE)

prior_summary(equality_model_prior)

equality %>% 
  add_fitted_draws(equality_model_prior, n = 100) %>%
  ggplot(aes(x = percent_urban, y = laws, color = historical)) +
    geom_line(aes(y = .value, group = paste(historical, .draw))) + 
    ylim(0, 100) +
  scale_color_manual(values = colors)

```

# 12.2 Simulating the posterior

```{r, cache=TRUE}

equality_model <- update(equality_model_prior, prior_PD = FALSE)

mcmc_trace(equality_model)
mcmc_dens_overlay(equality_model)
mcmc_acf(equality_model)

set.seed(1)
pp_check(equality_model, plotfun = "hist", nreps = 5) + 
  xlab("laws")
pp_check(equality_model) + 
  xlab("laws")

```

# 12.3 Interpreting the posterior

```{r}

equality %>%
  add_fitted_draws(equality_model, n = 50) %>%
  ggplot(aes(x = percent_urban, y = laws, color = historical)) +
    geom_line(aes(y = .value, group = paste(historical, .draw)), 
              alpha = .1) +
    geom_point(data = equality, size = 0.1) +
  scale_color_manual(values = colors)

tidy(equality_model, conf.int = TRUE, conf.level = 0.80)

```

# 12.4 Posterior prediction

```{r}

equality %>% 
  filter(state == "minnesota")

# Calculate posterior predictions
set.seed(84735)
mn_prediction <- posterior_predict(
  equality_model, newdata = data.frame(percent_urban = 73.3, 
                                       historical = "dem"))
head(mn_prediction, 3)

mcmc_hist(mn_prediction, binwidth = 1) + 
  geom_vline(xintercept = 4) + 
  xlab("Predicted number of laws in Minnesota")

# Predict number of laws for each parameter set in the chain
set.seed(84735)
as.data.frame(equality_model) %>% 
  mutate(log_lambda = `(Intercept)` + percent_urban*73.3 + 
           historicalgop*0 + historicalswing*0,
         lambda = exp(log_lambda),
         y_new = rpois(20000, lambda = lambda)) %>% 
  ggplot(aes(x = y_new)) + 
    stat_count()

```

# 12.5 Model evaluation

```{r, cache=TRUE}

# Simulate posterior predictive models for each state
set.seed(84735)
poisson_predictions <- posterior_predict(equality_model, newdata = equality)

# Plot the posterior predictive models for each state
ppc_intervals_grouped(equality$laws, yrep = poisson_predictions, 
                      x = equality$percent_urban, 
                      group = equality$historical,
                      prob = 0.5, prob_outer = 0.95,
                      facet_args = list(scales = "fixed"))

prediction_summary(model = equality_model, data = equality)

# Cross-validation
set.seed(84735)
poisson_cv <- prediction_summary_cv(model = equality_model, 
                                    data = equality, k = 10)

```

# 12.6 Negative Binomial regression for overdispersed counts

```{r}

# Load data
data(pulse_of_the_nation)
pulse <- pulse_of_the_nation %>% 
  filter(books < 100)

ggplot(pulse, aes(x = books)) + 
  geom_histogram(color = "white")
ggplot(pulse, aes(y = books, x = age)) + 
  geom_point()
ggplot(pulse, aes(y = books, x = wise_unwise)) + 
  geom_boxplot()

```

```{r, cache=TRUE}

books_poisson_sim <- stan_glm(
  books ~ age + wise_unwise, 
  data = pulse, family = poisson,
  prior_intercept = normal(0, 2.5, autoscale = TRUE),
  prior = normal(0, 2.5, autoscale = TRUE), 
  prior_aux = exponential(1, autoscale = TRUE),
  chains = 4, iter = 5000*2, seed = 84735)

pp_check(books_poisson_sim) + 
  xlab("books")

# Mean and variability in readership across all subjects
pulse %>% 
  summarize(mean = mean(books), var = var(books))

```

```{r, cache=TRUE}

books_negbin_sim <- stan_glm(
  books ~ age + wise_unwise, 
  data = pulse, family = neg_binomial_2,
  prior_intercept = normal(0, 2.5, autoscale = TRUE),
  prior = normal(0, 2.5, autoscale = TRUE), 
  prior_aux = exponential(1, autoscale = TRUE),
  chains = 4, iter = 5000*2, seed = 84735)

# Check out the priors
prior_summary(books_negbin_sim)

pp_check(books_negbin_sim) + 
  xlim(0, 75) + 
  xlab("books")

# Numerical summaries
tidy(books_negbin_sim, conf.int = TRUE, conf.level = 0.80)

```

