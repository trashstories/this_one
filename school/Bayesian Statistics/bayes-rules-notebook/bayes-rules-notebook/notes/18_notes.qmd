---
title: "18: Non-Normal Hierarchical Regression & Classification"
editor_options: 
  chunk_output_type: console
---

```{r, warning=FALSE, message=FALSE}

# Load packages
library(bayesrules)
library(tidyverse)
library(bayesplot)
library(rstanarm)
library(tidybayes)
library(broom.mixed)
library(janitor)

```

# 18.1 Hierarchical logistic regression

```{r}

# Import, rename, & clean data
data(climbers_sub)
climbers <- climbers_sub %>% 
  select(expedition_id, member_id, success, year, season,
         age, expedition_role, oxygen_used)

nrow(climbers)

climbers %>% 
  tabyl(success)

# Size per expedition
climbers_per_expedition <- climbers %>% 
  group_by(expedition_id) %>% 
  summarize(count = n())

# Number of expeditions
nrow(climbers_per_expedition)

climbers_per_expedition %>% 
  head(3)

# Calculate the success rate for each exhibition
expedition_success <- climbers %>% 
  group_by(expedition_id) %>% 
  summarize(success_rate = mean(success))

# Plot the success rates across exhibitions
ggplot(expedition_success, aes(x = success_rate)) + 
  geom_histogram(color = "white")

```

## 18.1.1 Model building & simulation

```{r, cache=TRUE}

# Calculate the success rate by age and oxygen use
data_by_age_oxygen <- climbers %>% 
  group_by(age, oxygen_used) %>% 
  summarize(success_rate = mean(success))

# Plot this relationship
ggplot(data_by_age_oxygen, aes(x = age, y = success_rate, 
                               color = oxygen_used)) + 
  geom_point()

climb_model <- stan_glmer(
  success ~ age + oxygen_used + (1 | expedition_id), 
  data = climbers, family = binomial,
  prior_intercept = normal(0, 2.5, autoscale = TRUE),
  prior = normal(0, 2.5, autoscale = TRUE), 
  prior_covariance = decov(reg = 1, conc = 1, shape = 1, scale = 1),
  chains = 4, iter = 5000*2, seed = 84735
)

# Confirm prior specifications
prior_summary(climb_model)

# MCMC diagnostics
mcmc_trace(climb_model, size = 0.1)
mcmc_dens_overlay(climb_model)
mcmc_acf(climb_model)
neff_ratio(climb_model)
rhat(climb_model)

# Define success rate function
success_rate <- function(x){mean(x == 1)}

# Posterior predictive check
pp_check(climb_model, nreps = 100,
         plotfun = "stat", stat = "success_rate") + 
  xlab("success rate")

```

## 18.1.2 Posterior analysis

```{r, cache=TRUE}

tidy(climb_model, effects = "fixed", conf.int = TRUE, conf.level = 0.80)

climbers %>%
  add_fitted_draws(climb_model, n = 100, re_formula = NA) %>%
  ggplot(aes(x = age, y = success, color = oxygen_used)) +
    geom_line(aes(y = .value, group = paste(oxygen_used, .draw)), 
              alpha = 0.1) + 
    labs(y = "probability of success")

```

## 18.1.3 Posterior classification

```{r, cache=TRUE}

# New expedition
new_expedition <- data.frame(
  age = c(20, 20, 60, 60), oxygen_used = c(FALSE, TRUE, FALSE, TRUE), 
  expedition_id = rep("new", 4))
new_expedition

# Posterior predictions of binary outcome
set.seed(84735)
binary_prediction <- posterior_predict(climb_model, newdata = new_expedition)

# First 3 prediction sets
head(binary_prediction, 3)

# Summarize the posterior predictions of Y
colMeans(binary_prediction)

```

## 18.1.4 Model evaluation

```{r, cache=TRUE}

set.seed(84735)
classification_summary(data = climbers, model = climb_model, cutoff = 0.5)

set.seed(84735)
classification_summary(data = climbers, model = climb_model, cutoff = 0.65)

```

# 18.2 Hierarchical Poisson & Negative Binomial regression

```{r, cache=TRUE}

# Load data
data(airbnb)

# Number of listings
nrow(airbnb)

# Number of neighborhoods
airbnb %>% 
  summarize(nlevels(neighborhood))

```


low sensitivity = false positives
low specificity = false negatives


