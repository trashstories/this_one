{"title":"13: Logistic Regression","markdown":{"yaml":{"title":"13: Logistic Regression","editor_options":{"chunk_output_type":"console"}},"headingText":"Load packages","containsRefs":false,"markdown":"\n\n```{r, warning=FALSE, message=FALSE}\n\nlibrary(bayesrules)\nlibrary(rstanarm)\nlibrary(bayesplot)\nlibrary(tidyverse)\nlibrary(tidybayes)\nlibrary(broom.mixed)\nlibrary(janitor)\n\n```\n\n# 13.8.1 Conceptual exercises\n\n## Exercise 13.1 (Normal vs logistic) \n\nFor each scenario, identify whether Normal or logistic regression is the appropriate tool for modeling $Y$ by $X$.\n\na. $Y =$ whether or not a person bikes to work, $X =$ the distance from the person’s home to work \n   -  **logistic**\nb. $Y =$ the number of minutes it takes a person to commute to work, $X =$ the distance from the person’s home to work  \n   - **normal**\nc. $Y =$ the number of minutes it takes a person to commute to work, $X =$ whether or not the person takes public transit to work  \n   - **normal**\n\n## Exercise 13.2 (What are the odds?) \n\nCalculate and interpret the odds for each event of interest below.\n\na. The probability of rain tomorrow is 0.8. \n   - $\\text{odds of rain } = \\frac{4/5}{1-4/5} = 4$ \n   - **It is 4 times more likely to rain than not rain tomorrow.**\nb. The probability of flipping 2 Heads in a row is 0.25.\n   - $\\text{2 heads in a row } = \\frac{1/4}{1-1/4} = \\frac{1}{3} $ \n   - **It is one third as likely to flip 2 heads in a row than not.**\nc. The log(odds) that your bus will be on time are 0.\n   - $\\text{on-time bus } = e^0 = 1 $ \n   - **The odds that your bus will be on time are 1, which means it's equally likely to be on time as it is to be late or early**\nd. The log(odds) that a person is left-handed are -1.386.\n   - $\\text{left-handed } = e^{-1.386} = 0.25 $ \n   - **The odds that a person is left-handed are approximately 0.25, which means that for every 1 left-handed person, there are 3 right-handed people.**\n   \n   e = 2.71828182845904523536028747135266249775724709369995....\n\n## Exercise 13.3 (What’s the probability?) \n\nCalculate and interpret the probability for each event of interest below.\n\na. The odds that your team will win the basketball game are 20 to 1.\n   - $\\text{win game } = \\pi = \\frac{20}{1 + 20} = 0.952381$\n   - **95.24% chance of winning**\nb. The odds of rain tomorrow are 0.5.\n   - $\\text{probability of rain } = \\pi = \\frac{{\\frac{1}{2}}}{1 + \\frac{1}{2}} = 0.3333333$\n   - **33.33% chance of rain tomorrow**\nc. The log(odds) of a certain candidate winning the election are 1.\n   - $\\text{win election } = \\frac{e^{1}}{1 + e^{1}} = 0.7311$\n   - **73.11% chance of winning**\nd. The log(odds) that a person likes pineapple pizza are -2.\n   - $\\text{likes pineapple } = \\frac{e^{-2}}{1 + e^{-2}} = 0.1192$\n   - **11.92% chance of liking pineapple on pizza**\n   \n*Not 100% sure how this are calculated...*\n\n## Exercise 13.4 (Logistic models) \n\nLet $Y$ indicate whether or not somebody believes that climate change is real and caused by people (TRUE or FALSE), and $X$ be their age. The simplified posterior median logistic regression model of $Y$ by $X$ provides insight into the relationship between the two. NOTE: This formula is loosely based on the `pulse_of_the_nation` survey results in the **bayesrules** package.\n\n\\begin{align}\n\\text{log(odds of belief in climate change)} = 1.43 - 0.02 \\text{age}\n\\end{align}\n\na. Express the posterior median model on the odds and probability scales.\nb. Interpret the age coefficient on the odds scale.\nc. Calculate the posterior median probability that a 60-year-old believes in climate change.\nd. Repeat part c for a 20-year-old.\n\n## Exercise 13.5 (Sensitivity vs specificity) \n\nContinuing our climate change belief analysis, the confusion matrix below summarizes the performance of our logistic model in classifying the beliefs of 1000 survey respondents, using a probability cut-off of 0.5.\n\n|     y      |   0   |   1   |\n| ---------- | ----- | ----- |\n| FALSE (0)  |\t50   |  300  |\n| TRUE (1)\t |  30\t |  620  |\n\na. Calculate and interpret the model’s overall accuracy.\nb. Calculate and interpret the model’s sensitivity.\nc. Calculate and interpret the model’s specificity.\nd. Suppose that researchers want to improve their ability to identify people that do not believe in climate change. How might they adjust their probability cut-off: Increase it or decrease it? Why?\n\n# 13.8.2 Applied exercises\n\n## Exercise 13.6 (Hotel bookings: getting started) \n\nPlans change. Hotel room bookings get canceled. In the next exercises, you’ll explore whether hotel cancellations might be predicted based upon the circumstances of a reservation. Throughout, utilize weakly informative priors and the `hotel_bookings` data in the **bayesrules** package. Your analysis will incorporate the following variables on hotel bookings:\n\n|  variable                |  notation  |\t meaning                                 |\n| ------------------------ | ---------- | ---------------------------------------- |\n| `is_canceled`\t           |    $Y$     | whether or not the booking was canceled  |\n| `lead_time`              |   $X_1$\t  | number of days between the booking       |\n|                          |            | and scheduled arrival                    |\n| `previous_cancellations` |   $X_2$    | number of previous times the guest has   |\n|                          |            | canceled a booking                       |\n| `is_repeated_guest`      |   $X_3$    | whether or not the booking guest is a    |\n|                          |            | repeat customer at the hotel             |\n| `average_daily_rate`     |   $X_4$    | the average per day cost of the hotel    |\n\na. What proportion of the sample bookings were canceled?\nb. Construct and discuss plots of `is_canceled` vs each of the four potential predictors above.\nc. Using formal mathematical notation, specify an appropriate Bayesian regression model of $Y$ by predictors $(X_1,X_2,X_3,X_4)$.\nd. Explain your choice for the structure of the data model.\n\n## Exercise 13.7 (Hotel bookings: simulation)\n\na. Simulate the posterior model of your regression parameters $(\\beta_0,\\beta_1,\\ldots,\\beta_4)$. Construct trace plots, density plots, and a `pp_check()` of the chain output.\nb. Report the posterior median model of hotel cancellations on each of the log(odds), odds, and probability scales.\nc. Construct 80% posterior credible intervals for your model coefficients. Interpret those for $\\beta_2$ and  $\\beta_3$ on the odds scale.\nd. Among the four predictors, which are significantly associated with hotel cancellations, both statistically and meaningfully? Explain.\n\n## Exercise 13.8 (Hotel bookings: classification rules)\n\na. How good is your model at anticipating whether a hotel booking will be canceled? Evaluate the classification accuracy using both the in-sample and cross-validation approaches, along with a 0.5 probability cut-off.\nb. Are the cross-validated and in-sample assessments of classification accuracy similar? Explain why this makes sense in the context of this analysis.\nc. Interpret the cross-validated overall accuracy, sensitivity, and specificity measures in the context of this analysis.\nd. Thinking like a hotel booking agent, you’d like to increase the sensitivity of your classifications to 0.75. Identify a probability cut-off that you could use to achieve this level while maintaining the highest possible specificity.\n\n## Exercise 13.9 (Hotel bookings: will they cancel?!)\n\nA guest that is new to a hotel and has only canceled a booking 1 time before, has booked a \\$100 per day hotel room 30 days in advance. Simulate, plot, and discuss the posterior predictive model of $Y$, whether or not the guest will cancel this booking.\nCome up with the features of another fictitious booking that’s more likely to be canceled than the booking in part a. Support your claim by simulating, plotting, and comparing this booking’s posterior predictive model of $Y$ to that in part a.\n","srcMarkdownNoYaml":"\n\n```{r, warning=FALSE, message=FALSE}\n\n# Load packages\nlibrary(bayesrules)\nlibrary(rstanarm)\nlibrary(bayesplot)\nlibrary(tidyverse)\nlibrary(tidybayes)\nlibrary(broom.mixed)\nlibrary(janitor)\n\n```\n\n# 13.8.1 Conceptual exercises\n\n## Exercise 13.1 (Normal vs logistic) \n\nFor each scenario, identify whether Normal or logistic regression is the appropriate tool for modeling $Y$ by $X$.\n\na. $Y =$ whether or not a person bikes to work, $X =$ the distance from the person’s home to work \n   -  **logistic**\nb. $Y =$ the number of minutes it takes a person to commute to work, $X =$ the distance from the person’s home to work  \n   - **normal**\nc. $Y =$ the number of minutes it takes a person to commute to work, $X =$ whether or not the person takes public transit to work  \n   - **normal**\n\n## Exercise 13.2 (What are the odds?) \n\nCalculate and interpret the odds for each event of interest below.\n\na. The probability of rain tomorrow is 0.8. \n   - $\\text{odds of rain } = \\frac{4/5}{1-4/5} = 4$ \n   - **It is 4 times more likely to rain than not rain tomorrow.**\nb. The probability of flipping 2 Heads in a row is 0.25.\n   - $\\text{2 heads in a row } = \\frac{1/4}{1-1/4} = \\frac{1}{3} $ \n   - **It is one third as likely to flip 2 heads in a row than not.**\nc. The log(odds) that your bus will be on time are 0.\n   - $\\text{on-time bus } = e^0 = 1 $ \n   - **The odds that your bus will be on time are 1, which means it's equally likely to be on time as it is to be late or early**\nd. The log(odds) that a person is left-handed are -1.386.\n   - $\\text{left-handed } = e^{-1.386} = 0.25 $ \n   - **The odds that a person is left-handed are approximately 0.25, which means that for every 1 left-handed person, there are 3 right-handed people.**\n   \n   e = 2.71828182845904523536028747135266249775724709369995....\n\n## Exercise 13.3 (What’s the probability?) \n\nCalculate and interpret the probability for each event of interest below.\n\na. The odds that your team will win the basketball game are 20 to 1.\n   - $\\text{win game } = \\pi = \\frac{20}{1 + 20} = 0.952381$\n   - **95.24% chance of winning**\nb. The odds of rain tomorrow are 0.5.\n   - $\\text{probability of rain } = \\pi = \\frac{{\\frac{1}{2}}}{1 + \\frac{1}{2}} = 0.3333333$\n   - **33.33% chance of rain tomorrow**\nc. The log(odds) of a certain candidate winning the election are 1.\n   - $\\text{win election } = \\frac{e^{1}}{1 + e^{1}} = 0.7311$\n   - **73.11% chance of winning**\nd. The log(odds) that a person likes pineapple pizza are -2.\n   - $\\text{likes pineapple } = \\frac{e^{-2}}{1 + e^{-2}} = 0.1192$\n   - **11.92% chance of liking pineapple on pizza**\n   \n*Not 100% sure how this are calculated...*\n\n## Exercise 13.4 (Logistic models) \n\nLet $Y$ indicate whether or not somebody believes that climate change is real and caused by people (TRUE or FALSE), and $X$ be their age. The simplified posterior median logistic regression model of $Y$ by $X$ provides insight into the relationship between the two. NOTE: This formula is loosely based on the `pulse_of_the_nation` survey results in the **bayesrules** package.\n\n\\begin{align}\n\\text{log(odds of belief in climate change)} = 1.43 - 0.02 \\text{age}\n\\end{align}\n\na. Express the posterior median model on the odds and probability scales.\nb. Interpret the age coefficient on the odds scale.\nc. Calculate the posterior median probability that a 60-year-old believes in climate change.\nd. Repeat part c for a 20-year-old.\n\n## Exercise 13.5 (Sensitivity vs specificity) \n\nContinuing our climate change belief analysis, the confusion matrix below summarizes the performance of our logistic model in classifying the beliefs of 1000 survey respondents, using a probability cut-off of 0.5.\n\n|     y      |   0   |   1   |\n| ---------- | ----- | ----- |\n| FALSE (0)  |\t50   |  300  |\n| TRUE (1)\t |  30\t |  620  |\n\na. Calculate and interpret the model’s overall accuracy.\nb. Calculate and interpret the model’s sensitivity.\nc. Calculate and interpret the model’s specificity.\nd. Suppose that researchers want to improve their ability to identify people that do not believe in climate change. How might they adjust their probability cut-off: Increase it or decrease it? Why?\n\n# 13.8.2 Applied exercises\n\n## Exercise 13.6 (Hotel bookings: getting started) \n\nPlans change. Hotel room bookings get canceled. In the next exercises, you’ll explore whether hotel cancellations might be predicted based upon the circumstances of a reservation. Throughout, utilize weakly informative priors and the `hotel_bookings` data in the **bayesrules** package. Your analysis will incorporate the following variables on hotel bookings:\n\n|  variable                |  notation  |\t meaning                                 |\n| ------------------------ | ---------- | ---------------------------------------- |\n| `is_canceled`\t           |    $Y$     | whether or not the booking was canceled  |\n| `lead_time`              |   $X_1$\t  | number of days between the booking       |\n|                          |            | and scheduled arrival                    |\n| `previous_cancellations` |   $X_2$    | number of previous times the guest has   |\n|                          |            | canceled a booking                       |\n| `is_repeated_guest`      |   $X_3$    | whether or not the booking guest is a    |\n|                          |            | repeat customer at the hotel             |\n| `average_daily_rate`     |   $X_4$    | the average per day cost of the hotel    |\n\na. What proportion of the sample bookings were canceled?\nb. Construct and discuss plots of `is_canceled` vs each of the four potential predictors above.\nc. Using formal mathematical notation, specify an appropriate Bayesian regression model of $Y$ by predictors $(X_1,X_2,X_3,X_4)$.\nd. Explain your choice for the structure of the data model.\n\n## Exercise 13.7 (Hotel bookings: simulation)\n\na. Simulate the posterior model of your regression parameters $(\\beta_0,\\beta_1,\\ldots,\\beta_4)$. Construct trace plots, density plots, and a `pp_check()` of the chain output.\nb. Report the posterior median model of hotel cancellations on each of the log(odds), odds, and probability scales.\nc. Construct 80% posterior credible intervals for your model coefficients. Interpret those for $\\beta_2$ and  $\\beta_3$ on the odds scale.\nd. Among the four predictors, which are significantly associated with hotel cancellations, both statistically and meaningfully? Explain.\n\n## Exercise 13.8 (Hotel bookings: classification rules)\n\na. How good is your model at anticipating whether a hotel booking will be canceled? Evaluate the classification accuracy using both the in-sample and cross-validation approaches, along with a 0.5 probability cut-off.\nb. Are the cross-validated and in-sample assessments of classification accuracy similar? Explain why this makes sense in the context of this analysis.\nc. Interpret the cross-validated overall accuracy, sensitivity, and specificity measures in the context of this analysis.\nd. Thinking like a hotel booking agent, you’d like to increase the sensitivity of your classifications to 0.75. Identify a probability cut-off that you could use to achieve this level while maintaining the highest possible specificity.\n\n## Exercise 13.9 (Hotel bookings: will they cancel?!)\n\nA guest that is new to a hotel and has only canceled a booking 1 time before, has booked a \\$100 per day hotel room 30 days in advance. Simulate, plot, and discuss the posterior predictive model of $Y$, whether or not the guest will cancel this booking.\nCome up with the features of another fictitious booking that’s more likely to be canceled than the booking in part a. Support your claim by simulating, plotting, and comparing this booking’s posterior predictive model of $Y$ to that in part a.\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"knitr"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true,"format-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","toc":true,"output-file":"13_exercises.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.3.433","theme":"../custom.scss","title":"13: Logistic Regression","editor_options":{"chunk_output_type":"console"}},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}