{
  "hash": "0c16a70f213404bbd4a4ee931128158e",
  "result": {
    "markdown": "---\ntitle: \"11: Extending the Normal Regression Model\"\neditor_options: \n  chunk_output_type: console\n---\n\n::: {.cell}\n\n```{.r .cell-code}\n# Load some packages\nlibrary(bayesrules)\nlibrary(rstanarm)\nlibrary(bayesplot)\nlibrary(tidyverse)\nlibrary(broom.mixed)\nlibrary(tidybayes)\n\n# Load the data\ndata(weather_WU)\nweather_WU %>% \n  group_by(location) %>% \n  tally()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2 × 2\n  location       n\n  <fct>      <int>\n1 Uluru        100\n2 Wollongong   100\n```\n:::\n\n```{.r .cell-code}\nweather_WU <- weather_WU %>% \n  select(location, windspeed9am, humidity9am, pressure9am, temp9am, temp3pm)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(weather_WU, aes(x = temp9am, y = temp3pm)) +\n  geom_point(size = 1)\n```\n\n::: {.cell-output-display}\n![](11_notes_files/figure-html/unnamed-chunk-1-1.png){width=672}\n:::\n:::\n\n::: {.cell hash='11_notes_cache/html/unnamed-chunk-2_e2b39d5b09fc692ba8186aa8f4618f73'}\n\n```{.r .cell-code}\nweather_model_1 <- stan_glm(\n  temp3pm ~ temp9am, \n  data = weather_WU, family = gaussian,\n  prior_intercept = normal(25, 5),\n  prior = normal(0, 2.5, autoscale = TRUE), \n  prior_aux = exponential(1, autoscale = TRUE),\n  chains = 4, iter = 5000*2, seed = 84735)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nSAMPLING FOR MODEL 'continuous' NOW (CHAIN 1).\nChain 1: \nChain 1: Gradient evaluation took 4e-05 seconds\nChain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.4 seconds.\nChain 1: Adjust your expectations accordingly!\nChain 1: \nChain 1: \nChain 1: Iteration:    1 / 10000 [  0%]  (Warmup)\nChain 1: Iteration: 1000 / 10000 [ 10%]  (Warmup)\nChain 1: Iteration: 2000 / 10000 [ 20%]  (Warmup)\nChain 1: Iteration: 3000 / 10000 [ 30%]  (Warmup)\nChain 1: Iteration: 4000 / 10000 [ 40%]  (Warmup)\nChain 1: Iteration: 5000 / 10000 [ 50%]  (Warmup)\nChain 1: Iteration: 5001 / 10000 [ 50%]  (Sampling)\nChain 1: Iteration: 6000 / 10000 [ 60%]  (Sampling)\nChain 1: Iteration: 7000 / 10000 [ 70%]  (Sampling)\nChain 1: Iteration: 8000 / 10000 [ 80%]  (Sampling)\nChain 1: Iteration: 9000 / 10000 [ 90%]  (Sampling)\nChain 1: Iteration: 10000 / 10000 [100%]  (Sampling)\nChain 1: \nChain 1:  Elapsed Time: 0.13 seconds (Warm-up)\nChain 1:                0.193 seconds (Sampling)\nChain 1:                0.323 seconds (Total)\nChain 1: \n\nSAMPLING FOR MODEL 'continuous' NOW (CHAIN 2).\nChain 2: \nChain 2: Gradient evaluation took 9e-06 seconds\nChain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.09 seconds.\nChain 2: Adjust your expectations accordingly!\nChain 2: \nChain 2: \nChain 2: Iteration:    1 / 10000 [  0%]  (Warmup)\nChain 2: Iteration: 1000 / 10000 [ 10%]  (Warmup)\nChain 2: Iteration: 2000 / 10000 [ 20%]  (Warmup)\nChain 2: Iteration: 3000 / 10000 [ 30%]  (Warmup)\nChain 2: Iteration: 4000 / 10000 [ 40%]  (Warmup)\nChain 2: Iteration: 5000 / 10000 [ 50%]  (Warmup)\nChain 2: Iteration: 5001 / 10000 [ 50%]  (Sampling)\nChain 2: Iteration: 6000 / 10000 [ 60%]  (Sampling)\nChain 2: Iteration: 7000 / 10000 [ 70%]  (Sampling)\nChain 2: Iteration: 8000 / 10000 [ 80%]  (Sampling)\nChain 2: Iteration: 9000 / 10000 [ 90%]  (Sampling)\nChain 2: Iteration: 10000 / 10000 [100%]  (Sampling)\nChain 2: \nChain 2:  Elapsed Time: 0.137 seconds (Warm-up)\nChain 2:                0.214 seconds (Sampling)\nChain 2:                0.351 seconds (Total)\nChain 2: \n\nSAMPLING FOR MODEL 'continuous' NOW (CHAIN 3).\nChain 3: \nChain 3: Gradient evaluation took 8e-06 seconds\nChain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.08 seconds.\nChain 3: Adjust your expectations accordingly!\nChain 3: \nChain 3: \nChain 3: Iteration:    1 / 10000 [  0%]  (Warmup)\nChain 3: Iteration: 1000 / 10000 [ 10%]  (Warmup)\nChain 3: Iteration: 2000 / 10000 [ 20%]  (Warmup)\nChain 3: Iteration: 3000 / 10000 [ 30%]  (Warmup)\nChain 3: Iteration: 4000 / 10000 [ 40%]  (Warmup)\nChain 3: Iteration: 5000 / 10000 [ 50%]  (Warmup)\nChain 3: Iteration: 5001 / 10000 [ 50%]  (Sampling)\nChain 3: Iteration: 6000 / 10000 [ 60%]  (Sampling)\nChain 3: Iteration: 7000 / 10000 [ 70%]  (Sampling)\nChain 3: Iteration: 8000 / 10000 [ 80%]  (Sampling)\nChain 3: Iteration: 9000 / 10000 [ 90%]  (Sampling)\nChain 3: Iteration: 10000 / 10000 [100%]  (Sampling)\nChain 3: \nChain 3:  Elapsed Time: 0.14 seconds (Warm-up)\nChain 3:                0.206 seconds (Sampling)\nChain 3:                0.346 seconds (Total)\nChain 3: \n\nSAMPLING FOR MODEL 'continuous' NOW (CHAIN 4).\nChain 4: \nChain 4: Gradient evaluation took 7e-06 seconds\nChain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.07 seconds.\nChain 4: Adjust your expectations accordingly!\nChain 4: \nChain 4: \nChain 4: Iteration:    1 / 10000 [  0%]  (Warmup)\nChain 4: Iteration: 1000 / 10000 [ 10%]  (Warmup)\nChain 4: Iteration: 2000 / 10000 [ 20%]  (Warmup)\nChain 4: Iteration: 3000 / 10000 [ 30%]  (Warmup)\nChain 4: Iteration: 4000 / 10000 [ 40%]  (Warmup)\nChain 4: Iteration: 5000 / 10000 [ 50%]  (Warmup)\nChain 4: Iteration: 5001 / 10000 [ 50%]  (Sampling)\nChain 4: Iteration: 6000 / 10000 [ 60%]  (Sampling)\nChain 4: Iteration: 7000 / 10000 [ 70%]  (Sampling)\nChain 4: Iteration: 8000 / 10000 [ 80%]  (Sampling)\nChain 4: Iteration: 9000 / 10000 [ 90%]  (Sampling)\nChain 4: Iteration: 10000 / 10000 [100%]  (Sampling)\nChain 4: \nChain 4:  Elapsed Time: 0.133 seconds (Warm-up)\nChain 4:                0.201 seconds (Sampling)\nChain 4:                0.334 seconds (Total)\nChain 4: \n```\n:::\n\n```{.r .cell-code}\n# Prior specification\nprior_summary(weather_model_1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nPriors for model 'weather_model_1' \n------\nIntercept (after predictors centered)\n ~ normal(location = 25, scale = 5)\n\nCoefficients\n  Specified prior:\n    ~ normal(location = 0, scale = 2.5)\n  Adjusted prior:\n    ~ normal(location = 0, scale = 3.1)\n\nAuxiliary (sigma)\n  Specified prior:\n    ~ exponential(rate = 1)\n  Adjusted prior:\n    ~ exponential(rate = 0.13)\n------\nSee help('prior_summary.stanreg') for more details\n```\n:::\n\n```{.r .cell-code}\n# MCMC diagnostics\nmcmc_trace(weather_model_1, size = 0.1)\n```\n\n::: {.cell-output-display}\n![](11_notes_files/figure-html/unnamed-chunk-2-1.png){width=672}\n:::\n\n```{.r .cell-code}\nmcmc_dens_overlay(weather_model_1)\n```\n\n::: {.cell-output-display}\n![](11_notes_files/figure-html/unnamed-chunk-2-2.png){width=672}\n:::\n\n```{.r .cell-code}\nmcmc_acf(weather_model_1)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: The `facets` argument of `facet_grid()` is deprecated as of ggplot2 2.2.0.\nℹ Please use the `rows` argument instead.\nℹ The deprecated feature was likely used in the bayesplot package.\n  Please report the issue at <https://github.com/stan-dev/bayesplot/issues/>.\n```\n:::\n\n::: {.cell-output-display}\n![](11_notes_files/figure-html/unnamed-chunk-2-3.png){width=672}\n:::\n\n```{.r .cell-code}\nneff_ratio(weather_model_1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n(Intercept)     temp9am       sigma \n    0.99710     1.00255     0.94530 \n```\n:::\n\n```{.r .cell-code}\nrhat(weather_model_1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n(Intercept)     temp9am       sigma \n  0.9999352   0.9999668   0.9999059 \n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Posterior credible intervals\nposterior_interval(weather_model_1, prob = 0.80)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                  10%      90%\n(Intercept) 2.9498083 5.448752\ntemp9am     0.9802648 1.102423\nsigma       3.8739305 4.409474\n```\n:::\n\n```{.r .cell-code}\npp_check(weather_model_1)\n```\n\n::: {.cell-output-display}\n![](11_notes_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n:::\n\n\n# 11.1 Utilizing a categorical predictor\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(weather_WU, aes(x = temp3pm, fill = location)) + \n  geom_density(alpha = 0.5)\n```\n\n::: {.cell-output-display}\n![](11_notes_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n:::\n\n\n## 11.1.2 Simulating the posterior\n\n\n::: {.cell hash='11_notes_cache/html/unnamed-chunk-5_3f7dbbcf694dd8e45deb1889529f58fa'}\n\n```{.r .cell-code}\nweather_model_2 <- stan_glm(\n  temp3pm ~ location,\n  data = weather_WU, family = gaussian,\n  prior_intercept = normal(25, 5),\n  prior = normal(0, 2.5, autoscale = TRUE), \n  prior_aux = exponential(1, autoscale = TRUE),\n  chains = 4, iter = 5000*2, seed = 84735)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nSAMPLING FOR MODEL 'continuous' NOW (CHAIN 1).\nChain 1: \nChain 1: Gradient evaluation took 1.4e-05 seconds\nChain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.14 seconds.\nChain 1: Adjust your expectations accordingly!\nChain 1: \nChain 1: \nChain 1: Iteration:    1 / 10000 [  0%]  (Warmup)\nChain 1: Iteration: 1000 / 10000 [ 10%]  (Warmup)\nChain 1: Iteration: 2000 / 10000 [ 20%]  (Warmup)\nChain 1: Iteration: 3000 / 10000 [ 30%]  (Warmup)\nChain 1: Iteration: 4000 / 10000 [ 40%]  (Warmup)\nChain 1: Iteration: 5000 / 10000 [ 50%]  (Warmup)\nChain 1: Iteration: 5001 / 10000 [ 50%]  (Sampling)\nChain 1: Iteration: 6000 / 10000 [ 60%]  (Sampling)\nChain 1: Iteration: 7000 / 10000 [ 70%]  (Sampling)\nChain 1: Iteration: 8000 / 10000 [ 80%]  (Sampling)\nChain 1: Iteration: 9000 / 10000 [ 90%]  (Sampling)\nChain 1: Iteration: 10000 / 10000 [100%]  (Sampling)\nChain 1: \nChain 1:  Elapsed Time: 0.128 seconds (Warm-up)\nChain 1:                0.2 seconds (Sampling)\nChain 1:                0.328 seconds (Total)\nChain 1: \n\nSAMPLING FOR MODEL 'continuous' NOW (CHAIN 2).\nChain 2: \nChain 2: Gradient evaluation took 1.1e-05 seconds\nChain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.11 seconds.\nChain 2: Adjust your expectations accordingly!\nChain 2: \nChain 2: \nChain 2: Iteration:    1 / 10000 [  0%]  (Warmup)\nChain 2: Iteration: 1000 / 10000 [ 10%]  (Warmup)\nChain 2: Iteration: 2000 / 10000 [ 20%]  (Warmup)\nChain 2: Iteration: 3000 / 10000 [ 30%]  (Warmup)\nChain 2: Iteration: 4000 / 10000 [ 40%]  (Warmup)\nChain 2: Iteration: 5000 / 10000 [ 50%]  (Warmup)\nChain 2: Iteration: 5001 / 10000 [ 50%]  (Sampling)\nChain 2: Iteration: 6000 / 10000 [ 60%]  (Sampling)\nChain 2: Iteration: 7000 / 10000 [ 70%]  (Sampling)\nChain 2: Iteration: 8000 / 10000 [ 80%]  (Sampling)\nChain 2: Iteration: 9000 / 10000 [ 90%]  (Sampling)\nChain 2: Iteration: 10000 / 10000 [100%]  (Sampling)\nChain 2: \nChain 2:  Elapsed Time: 0.136 seconds (Warm-up)\nChain 2:                0.203 seconds (Sampling)\nChain 2:                0.339 seconds (Total)\nChain 2: \n\nSAMPLING FOR MODEL 'continuous' NOW (CHAIN 3).\nChain 3: \nChain 3: Gradient evaluation took 7e-06 seconds\nChain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.07 seconds.\nChain 3: Adjust your expectations accordingly!\nChain 3: \nChain 3: \nChain 3: Iteration:    1 / 10000 [  0%]  (Warmup)\nChain 3: Iteration: 1000 / 10000 [ 10%]  (Warmup)\nChain 3: Iteration: 2000 / 10000 [ 20%]  (Warmup)\nChain 3: Iteration: 3000 / 10000 [ 30%]  (Warmup)\nChain 3: Iteration: 4000 / 10000 [ 40%]  (Warmup)\nChain 3: Iteration: 5000 / 10000 [ 50%]  (Warmup)\nChain 3: Iteration: 5001 / 10000 [ 50%]  (Sampling)\nChain 3: Iteration: 6000 / 10000 [ 60%]  (Sampling)\nChain 3: Iteration: 7000 / 10000 [ 70%]  (Sampling)\nChain 3: Iteration: 8000 / 10000 [ 80%]  (Sampling)\nChain 3: Iteration: 9000 / 10000 [ 90%]  (Sampling)\nChain 3: Iteration: 10000 / 10000 [100%]  (Sampling)\nChain 3: \nChain 3:  Elapsed Time: 0.136 seconds (Warm-up)\nChain 3:                0.204 seconds (Sampling)\nChain 3:                0.34 seconds (Total)\nChain 3: \n\nSAMPLING FOR MODEL 'continuous' NOW (CHAIN 4).\nChain 4: \nChain 4: Gradient evaluation took 1e-05 seconds\nChain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.1 seconds.\nChain 4: Adjust your expectations accordingly!\nChain 4: \nChain 4: \nChain 4: Iteration:    1 / 10000 [  0%]  (Warmup)\nChain 4: Iteration: 1000 / 10000 [ 10%]  (Warmup)\nChain 4: Iteration: 2000 / 10000 [ 20%]  (Warmup)\nChain 4: Iteration: 3000 / 10000 [ 30%]  (Warmup)\nChain 4: Iteration: 4000 / 10000 [ 40%]  (Warmup)\nChain 4: Iteration: 5000 / 10000 [ 50%]  (Warmup)\nChain 4: Iteration: 5001 / 10000 [ 50%]  (Sampling)\nChain 4: Iteration: 6000 / 10000 [ 60%]  (Sampling)\nChain 4: Iteration: 7000 / 10000 [ 70%]  (Sampling)\nChain 4: Iteration: 8000 / 10000 [ 80%]  (Sampling)\nChain 4: Iteration: 9000 / 10000 [ 90%]  (Sampling)\nChain 4: Iteration: 10000 / 10000 [100%]  (Sampling)\nChain 4: \nChain 4:  Elapsed Time: 0.142 seconds (Warm-up)\nChain 4:                0.199 seconds (Sampling)\nChain 4:                0.341 seconds (Total)\nChain 4: \n```\n:::\n\n```{.r .cell-code}\n# MCMC diagnostics\nmcmc_trace(weather_model_2, size = 0.1)\n```\n\n::: {.cell-output-display}\n![](11_notes_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n\n```{.r .cell-code}\nmcmc_dens_overlay(weather_model_2)\n```\n\n::: {.cell-output-display}\n![](11_notes_files/figure-html/unnamed-chunk-5-2.png){width=672}\n:::\n\n```{.r .cell-code}\nmcmc_acf(weather_model_2)\n```\n\n::: {.cell-output-display}\n![](11_notes_files/figure-html/unnamed-chunk-5-3.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Posterior summary statistics\ntidy(weather_model_2, effects = c(\"fixed\", \"aux\"),\n     conf.int = TRUE, conf.level = 0.80) %>% \n  select(-std.error)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 4 × 4\n  term               estimate conf.low conf.high\n  <chr>                 <dbl>    <dbl>     <dbl>\n1 (Intercept)           29.7     29.0      30.4 \n2 locationWollongong   -10.3    -11.3      -9.30\n3 sigma                  5.48     5.14      5.86\n4 mean_PPD              24.6     23.9      25.3 \n```\n:::\n\n```{.r .cell-code}\nas.data.frame(weather_model_2) %>% \n  mutate(uluru = `(Intercept)`, \n         wollongong = `(Intercept)` + locationWollongong) %>% \n  mcmc_areas(pars = c(\"uluru\", \"wollongong\"))\n```\n\n::: {.cell-output-display}\n![](11_notes_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n:::\n\n\n# 11.2 Utilizing two predictors\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(weather_WU, aes(y = temp3pm, x = temp9am, color = location)) + \n  geom_point() + \n  geom_smooth(method = \"lm\", se = FALSE)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n`geom_smooth()` using formula = 'y ~ x'\n```\n:::\n\n::: {.cell-output-display}\n![](11_notes_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n:::\n\n\n## 11.2.2 Understanding the priors\n\n\n::: {.cell hash='11_notes_cache/html/unnamed-chunk-8_7c5d3739704c5c3acff791c8381217c6'}\n\n```{.r .cell-code}\nweather_model_3_prior <- stan_glm(\n  temp3pm ~ temp9am + location,\n  data = weather_WU, family = gaussian, \n  prior_intercept = normal(25, 5),\n  prior = normal(0, 2.5, autoscale = TRUE), \n  prior_aux = exponential(1, autoscale = TRUE),\n  chains = 4, iter = 5000*2, seed = 84735,\n  prior_PD = TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nSAMPLING FOR MODEL 'continuous' NOW (CHAIN 1).\nChain 1: \nChain 1: Gradient evaluation took 9e-06 seconds\nChain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.09 seconds.\nChain 1: Adjust your expectations accordingly!\nChain 1: \nChain 1: \nChain 1: Iteration:    1 / 10000 [  0%]  (Warmup)\nChain 1: Iteration: 1000 / 10000 [ 10%]  (Warmup)\nChain 1: Iteration: 2000 / 10000 [ 20%]  (Warmup)\nChain 1: Iteration: 3000 / 10000 [ 30%]  (Warmup)\nChain 1: Iteration: 4000 / 10000 [ 40%]  (Warmup)\nChain 1: Iteration: 5000 / 10000 [ 50%]  (Warmup)\nChain 1: Iteration: 5001 / 10000 [ 50%]  (Sampling)\nChain 1: Iteration: 6000 / 10000 [ 60%]  (Sampling)\nChain 1: Iteration: 7000 / 10000 [ 70%]  (Sampling)\nChain 1: Iteration: 8000 / 10000 [ 80%]  (Sampling)\nChain 1: Iteration: 9000 / 10000 [ 90%]  (Sampling)\nChain 1: Iteration: 10000 / 10000 [100%]  (Sampling)\nChain 1: \nChain 1:  Elapsed Time: 0.136 seconds (Warm-up)\nChain 1:                0.244 seconds (Sampling)\nChain 1:                0.38 seconds (Total)\nChain 1: \n\nSAMPLING FOR MODEL 'continuous' NOW (CHAIN 2).\nChain 2: \nChain 2: Gradient evaluation took 5e-06 seconds\nChain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.05 seconds.\nChain 2: Adjust your expectations accordingly!\nChain 2: \nChain 2: \nChain 2: Iteration:    1 / 10000 [  0%]  (Warmup)\nChain 2: Iteration: 1000 / 10000 [ 10%]  (Warmup)\nChain 2: Iteration: 2000 / 10000 [ 20%]  (Warmup)\nChain 2: Iteration: 3000 / 10000 [ 30%]  (Warmup)\nChain 2: Iteration: 4000 / 10000 [ 40%]  (Warmup)\nChain 2: Iteration: 5000 / 10000 [ 50%]  (Warmup)\nChain 2: Iteration: 5001 / 10000 [ 50%]  (Sampling)\nChain 2: Iteration: 6000 / 10000 [ 60%]  (Sampling)\nChain 2: Iteration: 7000 / 10000 [ 70%]  (Sampling)\nChain 2: Iteration: 8000 / 10000 [ 80%]  (Sampling)\nChain 2: Iteration: 9000 / 10000 [ 90%]  (Sampling)\nChain 2: Iteration: 10000 / 10000 [100%]  (Sampling)\nChain 2: \nChain 2:  Elapsed Time: 0.13 seconds (Warm-up)\nChain 2:                0.131 seconds (Sampling)\nChain 2:                0.261 seconds (Total)\nChain 2: \n\nSAMPLING FOR MODEL 'continuous' NOW (CHAIN 3).\nChain 3: \nChain 3: Gradient evaluation took 6e-06 seconds\nChain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.06 seconds.\nChain 3: Adjust your expectations accordingly!\nChain 3: \nChain 3: \nChain 3: Iteration:    1 / 10000 [  0%]  (Warmup)\nChain 3: Iteration: 1000 / 10000 [ 10%]  (Warmup)\nChain 3: Iteration: 2000 / 10000 [ 20%]  (Warmup)\nChain 3: Iteration: 3000 / 10000 [ 30%]  (Warmup)\nChain 3: Iteration: 4000 / 10000 [ 40%]  (Warmup)\nChain 3: Iteration: 5000 / 10000 [ 50%]  (Warmup)\nChain 3: Iteration: 5001 / 10000 [ 50%]  (Sampling)\nChain 3: Iteration: 6000 / 10000 [ 60%]  (Sampling)\nChain 3: Iteration: 7000 / 10000 [ 70%]  (Sampling)\nChain 3: Iteration: 8000 / 10000 [ 80%]  (Sampling)\nChain 3: Iteration: 9000 / 10000 [ 90%]  (Sampling)\nChain 3: Iteration: 10000 / 10000 [100%]  (Sampling)\nChain 3: \nChain 3:  Elapsed Time: 0.115 seconds (Warm-up)\nChain 3:                0.161 seconds (Sampling)\nChain 3:                0.276 seconds (Total)\nChain 3: \n\nSAMPLING FOR MODEL 'continuous' NOW (CHAIN 4).\nChain 4: \nChain 4: Gradient evaluation took 4e-06 seconds\nChain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.04 seconds.\nChain 4: Adjust your expectations accordingly!\nChain 4: \nChain 4: \nChain 4: Iteration:    1 / 10000 [  0%]  (Warmup)\nChain 4: Iteration: 1000 / 10000 [ 10%]  (Warmup)\nChain 4: Iteration: 2000 / 10000 [ 20%]  (Warmup)\nChain 4: Iteration: 3000 / 10000 [ 30%]  (Warmup)\nChain 4: Iteration: 4000 / 10000 [ 40%]  (Warmup)\nChain 4: Iteration: 5000 / 10000 [ 50%]  (Warmup)\nChain 4: Iteration: 5001 / 10000 [ 50%]  (Sampling)\nChain 4: Iteration: 6000 / 10000 [ 60%]  (Sampling)\nChain 4: Iteration: 7000 / 10000 [ 70%]  (Sampling)\nChain 4: Iteration: 8000 / 10000 [ 80%]  (Sampling)\nChain 4: Iteration: 9000 / 10000 [ 90%]  (Sampling)\nChain 4: Iteration: 10000 / 10000 [100%]  (Sampling)\nChain 4: \nChain 4:  Elapsed Time: 0.109 seconds (Warm-up)\nChain 4:                0.113 seconds (Sampling)\nChain 4:                0.222 seconds (Total)\nChain 4: \n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(84735)\nweather_WU %>%\n  add_predicted_draws(weather_model_3_prior, n = 100) %>%\n  ggplot(aes(x = .prediction, group = .draw)) +\n    geom_density() + \n    xlab(\"temp3pm\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: \nIn add_predicted_draws(): The `n` argument is a deprecated alias for `ndraws`.\nUse the `ndraws` argument instead.\nSee help(\"tidybayes-deprecated\").\n```\n:::\n\n::: {.cell-output-display}\n![](11_notes_files/figure-html/unnamed-chunk-9-1.png){width=672}\n:::\n\n```{.r .cell-code}\nweather_WU %>%\n  add_fitted_draws(weather_model_3_prior, n = 100) %>%\n  ggplot(aes(x = temp9am, y = temp3pm, color = location)) +\n    geom_line(aes(y = .value, group = paste(location, .draw)))\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: `fitted_draws` and `add_fitted_draws` are deprecated as their names were confusing.\n- Use [add_]epred_draws() to get the expectation of the posterior predictive.\n- Use [add_]linpred_draws() to get the distribution of the linear predictor.\n- For example, you used [add_]fitted_draws(..., scale = \"response\"), which\n  means you most likely want [add_]epred_draws(...).\nNOTE: When updating to the new functions, note that the `model` parameter is now\n  named `object` and the `n` parameter is now named `ndraws`.\n```\n:::\n\n::: {.cell-output-display}\n![](11_notes_files/figure-html/unnamed-chunk-9-2.png){width=672}\n:::\n:::\n\n\n## 11.2.3 Simulating the posterior\n\n\n::: {.cell}\n\n```{.r .cell-code}\nweather_model_3 <- update(weather_model_3_prior, prior_PD = FALSE)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nSAMPLING FOR MODEL 'continuous' NOW (CHAIN 1).\nChain 1: \nChain 1: Gradient evaluation took 1.4e-05 seconds\nChain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.14 seconds.\nChain 1: Adjust your expectations accordingly!\nChain 1: \nChain 1: \nChain 1: Iteration:    1 / 10000 [  0%]  (Warmup)\nChain 1: Iteration: 1000 / 10000 [ 10%]  (Warmup)\nChain 1: Iteration: 2000 / 10000 [ 20%]  (Warmup)\nChain 1: Iteration: 3000 / 10000 [ 30%]  (Warmup)\nChain 1: Iteration: 4000 / 10000 [ 40%]  (Warmup)\nChain 1: Iteration: 5000 / 10000 [ 50%]  (Warmup)\nChain 1: Iteration: 5001 / 10000 [ 50%]  (Sampling)\nChain 1: Iteration: 6000 / 10000 [ 60%]  (Sampling)\nChain 1: Iteration: 7000 / 10000 [ 70%]  (Sampling)\nChain 1: Iteration: 8000 / 10000 [ 80%]  (Sampling)\nChain 1: Iteration: 9000 / 10000 [ 90%]  (Sampling)\nChain 1: Iteration: 10000 / 10000 [100%]  (Sampling)\nChain 1: \nChain 1:  Elapsed Time: 0.152 seconds (Warm-up)\nChain 1:                0.217 seconds (Sampling)\nChain 1:                0.369 seconds (Total)\nChain 1: \n\nSAMPLING FOR MODEL 'continuous' NOW (CHAIN 2).\nChain 2: \nChain 2: Gradient evaluation took 1.6e-05 seconds\nChain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.16 seconds.\nChain 2: Adjust your expectations accordingly!\nChain 2: \nChain 2: \nChain 2: Iteration:    1 / 10000 [  0%]  (Warmup)\nChain 2: Iteration: 1000 / 10000 [ 10%]  (Warmup)\nChain 2: Iteration: 2000 / 10000 [ 20%]  (Warmup)\nChain 2: Iteration: 3000 / 10000 [ 30%]  (Warmup)\nChain 2: Iteration: 4000 / 10000 [ 40%]  (Warmup)\nChain 2: Iteration: 5000 / 10000 [ 50%]  (Warmup)\nChain 2: Iteration: 5001 / 10000 [ 50%]  (Sampling)\nChain 2: Iteration: 6000 / 10000 [ 60%]  (Sampling)\nChain 2: Iteration: 7000 / 10000 [ 70%]  (Sampling)\nChain 2: Iteration: 8000 / 10000 [ 80%]  (Sampling)\nChain 2: Iteration: 9000 / 10000 [ 90%]  (Sampling)\nChain 2: Iteration: 10000 / 10000 [100%]  (Sampling)\nChain 2: \nChain 2:  Elapsed Time: 0.153 seconds (Warm-up)\nChain 2:                0.228 seconds (Sampling)\nChain 2:                0.381 seconds (Total)\nChain 2: \n\nSAMPLING FOR MODEL 'continuous' NOW (CHAIN 3).\nChain 3: \nChain 3: Gradient evaluation took 7e-06 seconds\nChain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.07 seconds.\nChain 3: Adjust your expectations accordingly!\nChain 3: \nChain 3: \nChain 3: Iteration:    1 / 10000 [  0%]  (Warmup)\nChain 3: Iteration: 1000 / 10000 [ 10%]  (Warmup)\nChain 3: Iteration: 2000 / 10000 [ 20%]  (Warmup)\nChain 3: Iteration: 3000 / 10000 [ 30%]  (Warmup)\nChain 3: Iteration: 4000 / 10000 [ 40%]  (Warmup)\nChain 3: Iteration: 5000 / 10000 [ 50%]  (Warmup)\nChain 3: Iteration: 5001 / 10000 [ 50%]  (Sampling)\nChain 3: Iteration: 6000 / 10000 [ 60%]  (Sampling)\nChain 3: Iteration: 7000 / 10000 [ 70%]  (Sampling)\nChain 3: Iteration: 8000 / 10000 [ 80%]  (Sampling)\nChain 3: Iteration: 9000 / 10000 [ 90%]  (Sampling)\nChain 3: Iteration: 10000 / 10000 [100%]  (Sampling)\nChain 3: \nChain 3:  Elapsed Time: 0.153 seconds (Warm-up)\nChain 3:                0.215 seconds (Sampling)\nChain 3:                0.368 seconds (Total)\nChain 3: \n\nSAMPLING FOR MODEL 'continuous' NOW (CHAIN 4).\nChain 4: \nChain 4: Gradient evaluation took 7e-06 seconds\nChain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.07 seconds.\nChain 4: Adjust your expectations accordingly!\nChain 4: \nChain 4: \nChain 4: Iteration:    1 / 10000 [  0%]  (Warmup)\nChain 4: Iteration: 1000 / 10000 [ 10%]  (Warmup)\nChain 4: Iteration: 2000 / 10000 [ 20%]  (Warmup)\nChain 4: Iteration: 3000 / 10000 [ 30%]  (Warmup)\nChain 4: Iteration: 4000 / 10000 [ 40%]  (Warmup)\nChain 4: Iteration: 5000 / 10000 [ 50%]  (Warmup)\nChain 4: Iteration: 5001 / 10000 [ 50%]  (Sampling)\nChain 4: Iteration: 6000 / 10000 [ 60%]  (Sampling)\nChain 4: Iteration: 7000 / 10000 [ 70%]  (Sampling)\nChain 4: Iteration: 8000 / 10000 [ 80%]  (Sampling)\nChain 4: Iteration: 9000 / 10000 [ 90%]  (Sampling)\nChain 4: Iteration: 10000 / 10000 [100%]  (Sampling)\nChain 4: \nChain 4:  Elapsed Time: 0.159 seconds (Warm-up)\nChain 4:                0.237 seconds (Sampling)\nChain 4:                0.396 seconds (Total)\nChain 4: \n```\n:::\n\n```{.r .cell-code}\nhead(as.data.frame(weather_model_3), 3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  (Intercept)   temp9am locationWollongong    sigma\n1    13.04657 0.8016891          -7.663020 2.392109\n2    12.73136 0.8174191          -7.838690 2.444850\n3    11.81295 0.8615380          -7.647937 2.413606\n```\n:::\n\n```{.r .cell-code}\nweather_WU %>%\n  add_fitted_draws(weather_model_3, n = 100) %>%\n  ggplot(aes(x = temp9am, y = temp3pm, color = location)) +\n    geom_line(aes(y = .value, group = paste(location, .draw)), alpha = .1) +\n    geom_point(data = weather_WU, size = 0.5)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: `fitted_draws` and `add_fitted_draws` are deprecated as their names were confusing.\n- Use [add_]epred_draws() to get the expectation of the posterior predictive.\n- Use [add_]linpred_draws() to get the distribution of the linear predictor.\n- For example, you used [add_]fitted_draws(..., scale = \"response\"), which\n  means you most likely want [add_]epred_draws(...).\nNOTE: When updating to the new functions, note that the `model` parameter is now\n  named `object` and the `n` parameter is now named `ndraws`.\n```\n:::\n\n::: {.cell-output-display}\n![](11_notes_files/figure-html/unnamed-chunk-10-1.png){width=672}\n:::\n:::\n\n\n## 11.2.4 Posterior prediction\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Simulate a set of predictions\nset.seed(84735)\ntemp3pm_prediction <- posterior_predict(\n  weather_model_3,\n  newdata = data.frame(temp9am = c(10, 10), \n                       location = c(\"Uluru\", \"Wollongong\")))\n\n# Plot the posterior predictive models\nmcmc_areas(temp3pm_prediction) +\n  ggplot2::scale_y_discrete(labels = c(\"Uluru\", \"Wollongong\")) + \n  xlab(\"temp3pm\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nScale for y is already present.\nAdding another scale for y, which will replace the existing scale.\n```\n:::\n\n::: {.cell-output-display}\n![](11_notes_files/figure-html/unnamed-chunk-11-1.png){width=672}\n:::\n:::\n\n\n# 11.3 Optional: Utilizing interaction terms\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(weather_WU, aes(y = temp3pm, x = humidity9am, color = location)) +\n  geom_point(size = 1) + \n  geom_smooth(method = \"lm\", se = FALSE)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n`geom_smooth()` using formula = 'y ~ x'\n```\n:::\n\n::: {.cell-output-display}\n![](11_notes_files/figure-html/unnamed-chunk-12-1.png){width=672}\n:::\n:::\n\n\n## 11.3.2 Simulating the posterior\n\n\n::: {.cell hash='11_notes_cache/html/unnamed-chunk-13_b53d662fc481c58abd07286702a3c484'}\n\n```{.r .cell-code}\ninteraction_model <- stan_glm(\n  temp3pm ~ location + humidity9am + location:humidity9am, \n  data = weather_WU, family = gaussian,\n  prior_intercept = normal(25, 5),\n  prior = normal(0, 2.5, autoscale = TRUE), \n  prior_aux = exponential(1, autoscale = TRUE),\n  chains = 4, iter = 5000*2, seed = 84735)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nSAMPLING FOR MODEL 'continuous' NOW (CHAIN 1).\nChain 1: \nChain 1: Gradient evaluation took 1.8e-05 seconds\nChain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.18 seconds.\nChain 1: Adjust your expectations accordingly!\nChain 1: \nChain 1: \nChain 1: Iteration:    1 / 10000 [  0%]  (Warmup)\nChain 1: Iteration: 1000 / 10000 [ 10%]  (Warmup)\nChain 1: Iteration: 2000 / 10000 [ 20%]  (Warmup)\nChain 1: Iteration: 3000 / 10000 [ 30%]  (Warmup)\nChain 1: Iteration: 4000 / 10000 [ 40%]  (Warmup)\nChain 1: Iteration: 5000 / 10000 [ 50%]  (Warmup)\nChain 1: Iteration: 5001 / 10000 [ 50%]  (Sampling)\nChain 1: Iteration: 6000 / 10000 [ 60%]  (Sampling)\nChain 1: Iteration: 7000 / 10000 [ 70%]  (Sampling)\nChain 1: Iteration: 8000 / 10000 [ 80%]  (Sampling)\nChain 1: Iteration: 9000 / 10000 [ 90%]  (Sampling)\nChain 1: Iteration: 10000 / 10000 [100%]  (Sampling)\nChain 1: \nChain 1:  Elapsed Time: 0.5 seconds (Warm-up)\nChain 1:                0.592 seconds (Sampling)\nChain 1:                1.092 seconds (Total)\nChain 1: \n\nSAMPLING FOR MODEL 'continuous' NOW (CHAIN 2).\nChain 2: \nChain 2: Gradient evaluation took 1.1e-05 seconds\nChain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.11 seconds.\nChain 2: Adjust your expectations accordingly!\nChain 2: \nChain 2: \nChain 2: Iteration:    1 / 10000 [  0%]  (Warmup)\nChain 2: Iteration: 1000 / 10000 [ 10%]  (Warmup)\nChain 2: Iteration: 2000 / 10000 [ 20%]  (Warmup)\nChain 2: Iteration: 3000 / 10000 [ 30%]  (Warmup)\nChain 2: Iteration: 4000 / 10000 [ 40%]  (Warmup)\nChain 2: Iteration: 5000 / 10000 [ 50%]  (Warmup)\nChain 2: Iteration: 5001 / 10000 [ 50%]  (Sampling)\nChain 2: Iteration: 6000 / 10000 [ 60%]  (Sampling)\nChain 2: Iteration: 7000 / 10000 [ 70%]  (Sampling)\nChain 2: Iteration: 8000 / 10000 [ 80%]  (Sampling)\nChain 2: Iteration: 9000 / 10000 [ 90%]  (Sampling)\nChain 2: Iteration: 10000 / 10000 [100%]  (Sampling)\nChain 2: \nChain 2:  Elapsed Time: 0.501 seconds (Warm-up)\nChain 2:                0.559 seconds (Sampling)\nChain 2:                1.06 seconds (Total)\nChain 2: \n\nSAMPLING FOR MODEL 'continuous' NOW (CHAIN 3).\nChain 3: \nChain 3: Gradient evaluation took 8e-06 seconds\nChain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.08 seconds.\nChain 3: Adjust your expectations accordingly!\nChain 3: \nChain 3: \nChain 3: Iteration:    1 / 10000 [  0%]  (Warmup)\nChain 3: Iteration: 1000 / 10000 [ 10%]  (Warmup)\nChain 3: Iteration: 2000 / 10000 [ 20%]  (Warmup)\nChain 3: Iteration: 3000 / 10000 [ 30%]  (Warmup)\nChain 3: Iteration: 4000 / 10000 [ 40%]  (Warmup)\nChain 3: Iteration: 5000 / 10000 [ 50%]  (Warmup)\nChain 3: Iteration: 5001 / 10000 [ 50%]  (Sampling)\nChain 3: Iteration: 6000 / 10000 [ 60%]  (Sampling)\nChain 3: Iteration: 7000 / 10000 [ 70%]  (Sampling)\nChain 3: Iteration: 8000 / 10000 [ 80%]  (Sampling)\nChain 3: Iteration: 9000 / 10000 [ 90%]  (Sampling)\nChain 3: Iteration: 10000 / 10000 [100%]  (Sampling)\nChain 3: \nChain 3:  Elapsed Time: 0.464 seconds (Warm-up)\nChain 3:                0.624 seconds (Sampling)\nChain 3:                1.088 seconds (Total)\nChain 3: \n\nSAMPLING FOR MODEL 'continuous' NOW (CHAIN 4).\nChain 4: \nChain 4: Gradient evaluation took 7e-06 seconds\nChain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.07 seconds.\nChain 4: Adjust your expectations accordingly!\nChain 4: \nChain 4: \nChain 4: Iteration:    1 / 10000 [  0%]  (Warmup)\nChain 4: Iteration: 1000 / 10000 [ 10%]  (Warmup)\nChain 4: Iteration: 2000 / 10000 [ 20%]  (Warmup)\nChain 4: Iteration: 3000 / 10000 [ 30%]  (Warmup)\nChain 4: Iteration: 4000 / 10000 [ 40%]  (Warmup)\nChain 4: Iteration: 5000 / 10000 [ 50%]  (Warmup)\nChain 4: Iteration: 5001 / 10000 [ 50%]  (Sampling)\nChain 4: Iteration: 6000 / 10000 [ 60%]  (Sampling)\nChain 4: Iteration: 7000 / 10000 [ 70%]  (Sampling)\nChain 4: Iteration: 8000 / 10000 [ 80%]  (Sampling)\nChain 4: Iteration: 9000 / 10000 [ 90%]  (Sampling)\nChain 4: Iteration: 10000 / 10000 [100%]  (Sampling)\nChain 4: \nChain 4:  Elapsed Time: 0.467 seconds (Warm-up)\nChain 4:                0.601 seconds (Sampling)\nChain 4:                1.068 seconds (Total)\nChain 4: \n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Posterior summary statistics\ntidy(interaction_model, effects = c(\"fixed\", \"aux\"))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 × 3\n  term                           estimate std.error\n  <chr>                             <dbl>     <dbl>\n1 (Intercept)                      37.6      0.909 \n2 locationWollongong              -21.8      2.31  \n3 humidity9am                      -0.190    0.0193\n4 locationWollongong:humidity9am    0.246    0.0372\n5 sigma                             4.47     0.229 \n6 mean_PPD                         24.6      0.453 \n```\n:::\n\n```{.r .cell-code}\nposterior_interval(interaction_model, prob = 0.80, \n                   pars = \"locationWollongong:humidity9am\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                                     10%       90%\nlocationWollongong:humidity9am 0.1977762 0.2930092\n```\n:::\n\n```{.r .cell-code}\nweather_WU %>%\n  add_fitted_draws(interaction_model, n = 200) %>%\n  ggplot(aes(x = humidity9am, y = temp3pm, color = location)) +\n    geom_line(aes(y = .value, group = paste(location, .draw)), alpha = 0.1)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: `fitted_draws` and `add_fitted_draws` are deprecated as their names were confusing.\n- Use [add_]epred_draws() to get the expectation of the posterior predictive.\n- Use [add_]linpred_draws() to get the distribution of the linear predictor.\n- For example, you used [add_]fitted_draws(..., scale = \"response\"), which\n  means you most likely want [add_]epred_draws(...).\nNOTE: When updating to the new functions, note that the `model` parameter is now\n  named `object` and the `n` parameter is now named `ndraws`.\n```\n:::\n\n::: {.cell-output-display}\n![](11_notes_files/figure-html/unnamed-chunk-14-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ndata(bike_users)\nbike_users %>% \n  group_by(user) %>% \n  tally()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2 × 2\n  user           n\n  <fct>      <int>\n1 casual       267\n2 registered   267\n```\n:::\n\n```{.r .cell-code}\nbike_casual <- bike_users %>% \n  filter(user == \"casual\")\nbike_registered <- bike_users %>% \n  filter(user == \"registered\")\n\nggplot(bike_casual, aes(y = rides, x = temp_actual, color = weekend)) + \n  geom_smooth(method = \"lm\", se = FALSE) + \n  labs(title = \"casual riders\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n`geom_smooth()` using formula = 'y ~ x'\n```\n:::\n\n::: {.cell-output-display}\n![](11_notes_files/figure-html/unnamed-chunk-15-1.png){width=672}\n:::\n\n```{.r .cell-code}\nggplot(bike_casual, aes(y = rides, x = temp_actual, color = humidity)) + \n  geom_point()\n```\n\n::: {.cell-output-display}\n![](11_notes_files/figure-html/unnamed-chunk-15-2.png){width=672}\n:::\n\n```{.r .cell-code}\nggplot(bike_casual, \n       aes(y = rides, x = temp_actual, \n           color = cut(humidity, 2, labels = c(\"low\",\"high\")))) + \n  geom_smooth(method = \"lm\", se = FALSE) + \n  labs(color = \"humidity_level\") + \n  lims(y = c(0, 2500))\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n`geom_smooth()` using formula = 'y ~ x'\n```\n:::\n\n::: {.cell-output-display}\n![](11_notes_files/figure-html/unnamed-chunk-15-3.png){width=672}\n:::\n\n```{.r .cell-code}\n# Example syntax\nggplot(bike_users, aes(y = rides, x = user, fill = weather_cat)) + \n  geom_boxplot() \n```\n\n::: {.cell-output-display}\n![](11_notes_files/figure-html/unnamed-chunk-15-4.png){width=672}\n:::\n:::\n\n\n# 11.4 Dreaming bigger: Utilizing more than 2 predictors!\n\n\n::: {.cell}\n\n```{.r .cell-code}\nweather_WU %>% \n  names()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"location\"     \"windspeed9am\" \"humidity9am\"  \"pressure9am\"  \"temp9am\"     \n[6] \"temp3pm\"     \n```\n:::\n\n```{.r .cell-code}\nweather_model_4 <- stan_glm(\n  temp3pm ~ .,\n  data = weather_WU, family = gaussian, \n  prior_intercept = normal(25, 5),\n  prior = normal(0, 2.5, autoscale = TRUE), \n  prior_aux = exponential(1, autoscale = TRUE),\n  chains = 4, iter = 5000*2, seed = 84735)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nSAMPLING FOR MODEL 'continuous' NOW (CHAIN 1).\nChain 1: \nChain 1: Gradient evaluation took 1.7e-05 seconds\nChain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.17 seconds.\nChain 1: Adjust your expectations accordingly!\nChain 1: \nChain 1: \nChain 1: Iteration:    1 / 10000 [  0%]  (Warmup)\nChain 1: Iteration: 1000 / 10000 [ 10%]  (Warmup)\nChain 1: Iteration: 2000 / 10000 [ 20%]  (Warmup)\nChain 1: Iteration: 3000 / 10000 [ 30%]  (Warmup)\nChain 1: Iteration: 4000 / 10000 [ 40%]  (Warmup)\nChain 1: Iteration: 5000 / 10000 [ 50%]  (Warmup)\nChain 1: Iteration: 5001 / 10000 [ 50%]  (Sampling)\nChain 1: Iteration: 6000 / 10000 [ 60%]  (Sampling)\nChain 1: Iteration: 7000 / 10000 [ 70%]  (Sampling)\nChain 1: Iteration: 8000 / 10000 [ 80%]  (Sampling)\nChain 1: Iteration: 9000 / 10000 [ 90%]  (Sampling)\nChain 1: Iteration: 10000 / 10000 [100%]  (Sampling)\nChain 1: \nChain 1:  Elapsed Time: 0.257 seconds (Warm-up)\nChain 1:                0.333 seconds (Sampling)\nChain 1:                0.59 seconds (Total)\nChain 1: \n\nSAMPLING FOR MODEL 'continuous' NOW (CHAIN 2).\nChain 2: \nChain 2: Gradient evaluation took 8e-06 seconds\nChain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.08 seconds.\nChain 2: Adjust your expectations accordingly!\nChain 2: \nChain 2: \nChain 2: Iteration:    1 / 10000 [  0%]  (Warmup)\nChain 2: Iteration: 1000 / 10000 [ 10%]  (Warmup)\nChain 2: Iteration: 2000 / 10000 [ 20%]  (Warmup)\nChain 2: Iteration: 3000 / 10000 [ 30%]  (Warmup)\nChain 2: Iteration: 4000 / 10000 [ 40%]  (Warmup)\nChain 2: Iteration: 5000 / 10000 [ 50%]  (Warmup)\nChain 2: Iteration: 5001 / 10000 [ 50%]  (Sampling)\nChain 2: Iteration: 6000 / 10000 [ 60%]  (Sampling)\nChain 2: Iteration: 7000 / 10000 [ 70%]  (Sampling)\nChain 2: Iteration: 8000 / 10000 [ 80%]  (Sampling)\nChain 2: Iteration: 9000 / 10000 [ 90%]  (Sampling)\nChain 2: Iteration: 10000 / 10000 [100%]  (Sampling)\nChain 2: \nChain 2:  Elapsed Time: 0.281 seconds (Warm-up)\nChain 2:                0.345 seconds (Sampling)\nChain 2:                0.626 seconds (Total)\nChain 2: \n\nSAMPLING FOR MODEL 'continuous' NOW (CHAIN 3).\nChain 3: \nChain 3: Gradient evaluation took 7e-06 seconds\nChain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.07 seconds.\nChain 3: Adjust your expectations accordingly!\nChain 3: \nChain 3: \nChain 3: Iteration:    1 / 10000 [  0%]  (Warmup)\nChain 3: Iteration: 1000 / 10000 [ 10%]  (Warmup)\nChain 3: Iteration: 2000 / 10000 [ 20%]  (Warmup)\nChain 3: Iteration: 3000 / 10000 [ 30%]  (Warmup)\nChain 3: Iteration: 4000 / 10000 [ 40%]  (Warmup)\nChain 3: Iteration: 5000 / 10000 [ 50%]  (Warmup)\nChain 3: Iteration: 5001 / 10000 [ 50%]  (Sampling)\nChain 3: Iteration: 6000 / 10000 [ 60%]  (Sampling)\nChain 3: Iteration: 7000 / 10000 [ 70%]  (Sampling)\nChain 3: Iteration: 8000 / 10000 [ 80%]  (Sampling)\nChain 3: Iteration: 9000 / 10000 [ 90%]  (Sampling)\nChain 3: Iteration: 10000 / 10000 [100%]  (Sampling)\nChain 3: \nChain 3:  Elapsed Time: 0.279 seconds (Warm-up)\nChain 3:                0.28 seconds (Sampling)\nChain 3:                0.559 seconds (Total)\nChain 3: \n\nSAMPLING FOR MODEL 'continuous' NOW (CHAIN 4).\nChain 4: \nChain 4: Gradient evaluation took 8e-06 seconds\nChain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.08 seconds.\nChain 4: Adjust your expectations accordingly!\nChain 4: \nChain 4: \nChain 4: Iteration:    1 / 10000 [  0%]  (Warmup)\nChain 4: Iteration: 1000 / 10000 [ 10%]  (Warmup)\nChain 4: Iteration: 2000 / 10000 [ 20%]  (Warmup)\nChain 4: Iteration: 3000 / 10000 [ 30%]  (Warmup)\nChain 4: Iteration: 4000 / 10000 [ 40%]  (Warmup)\nChain 4: Iteration: 5000 / 10000 [ 50%]  (Warmup)\nChain 4: Iteration: 5001 / 10000 [ 50%]  (Sampling)\nChain 4: Iteration: 6000 / 10000 [ 60%]  (Sampling)\nChain 4: Iteration: 7000 / 10000 [ 70%]  (Sampling)\nChain 4: Iteration: 8000 / 10000 [ 80%]  (Sampling)\nChain 4: Iteration: 9000 / 10000 [ 90%]  (Sampling)\nChain 4: Iteration: 10000 / 10000 [100%]  (Sampling)\nChain 4: \nChain 4:  Elapsed Time: 0.268 seconds (Warm-up)\nChain 4:                0.348 seconds (Sampling)\nChain 4:                0.616 seconds (Total)\nChain 4: \n```\n:::\n\n```{.r .cell-code}\n# Confirm prior specification\nprior_summary(weather_model_4)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nPriors for model 'weather_model_4' \n------\nIntercept (after predictors centered)\n ~ normal(location = 25, scale = 5)\n\nCoefficients\n  Specified prior:\n    ~ normal(location = [0,0,0,...], scale = [2.5,2.5,2.5,...])\n  Adjusted prior:\n    ~ normal(location = [0,0,0,...], scale = [37.52, 2.37, 0.82,...])\n\nAuxiliary (sigma)\n  Specified prior:\n    ~ exponential(rate = 1)\n  Adjusted prior:\n    ~ exponential(rate = 0.13)\n------\nSee help('prior_summary.stanreg') for more details\n```\n:::\n\n```{.r .cell-code}\n# Check MCMC diagnostics\nmcmc_trace(weather_model_4)\n```\n\n::: {.cell-output-display}\n![](11_notes_files/figure-html/unnamed-chunk-16-1.png){width=672}\n:::\n\n```{.r .cell-code}\nmcmc_dens_overlay(weather_model_4)\n```\n\n::: {.cell-output-display}\n![](11_notes_files/figure-html/unnamed-chunk-16-2.png){width=672}\n:::\n\n```{.r .cell-code}\nmcmc_acf(weather_model_4)\n```\n\n::: {.cell-output-display}\n![](11_notes_files/figure-html/unnamed-chunk-16-3.png){width=672}\n:::\n\n```{.r .cell-code}\n# Posterior summaries\nposterior_interval(weather_model_4, prob = 0.95)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                           2.5%       97.5%\n(Intercept)        -23.92281904 98.96184755\nlocationWollongong  -7.19827046 -5.66547243\nwindspeed9am        -0.05491239  0.02975158\nhumidity9am         -0.05169826 -0.01510501\npressure9am         -0.08255876  0.03669673\ntemp9am              0.72892547  0.87455883\nsigma                2.10496742  2.57179996\n```\n:::\n:::\n\n\n# 11.5 Model evaluation & comparison\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Posterior predictive checks. For example:\npp_check(weather_model_1)\n```\n\n::: {.cell-output-display}\n![](11_notes_files/figure-html/unnamed-chunk-17-1.png){width=672}\n:::\n:::\n\n\n## 11.5.1 Evaluating predictive accuracy using visualizations\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(84735)\npredictions_1 <- posterior_predict(weather_model_1, newdata = weather_WU)\n\n# Posterior predictive models for weather_model_1\nppc_intervals(weather_WU$temp3pm, yrep = predictions_1, \n              x = weather_WU$temp9am, prob = 0.5, prob_outer = 0.95) + \n  labs(x = \"temp9am\", y = \"temp3pm\")\n```\n\n::: {.cell-output-display}\n![](11_notes_files/figure-html/unnamed-chunk-18-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(84735)\nprediction_summary_cv(model = weather_model_1, data = weather_WU, k = 10)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n$folds\n   fold      mae mae_scaled within_50 within_95\n1     1 3.564498  0.8445706      0.30      1.00\n2     2 2.725559  0.6619840      0.55      0.90\n3     3 3.023616  0.7514263      0.40      0.85\n4     4 3.199433  0.7578761      0.50      1.00\n5     5 3.790749  0.9170231      0.25      1.00\n6     6 3.372913  0.7968418      0.45      1.00\n7     7 2.880373  0.6953989      0.50      0.95\n8     8 2.840581  0.6738942      0.50      1.00\n9     9 4.096178  0.9900088      0.30      1.00\n10   10 3.355105  0.8062387      0.30      1.00\n\n$cv\n       mae mae_scaled within_50 within_95\n1 3.284901  0.7895262     0.405      0.97\n```\n:::\n:::\n\n\n## 11.5.3 Evaluating predictive accuracy using ELPD\n\n\n::: {.cell hash='11_notes_cache/html/unnamed-chunk-20_2903c00b92ebce1bedbefd6d4241554a'}\n\n```{.r .cell-code}\n# Calculate ELPD for the 4 models\nset.seed(84735)\nloo_1 <- loo(weather_model_1)\nloo_2 <- loo(weather_model_2)\nloo_3 <- loo(weather_model_3)\nloo_4 <- loo(weather_model_4)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Found 1 observation(s) with a pareto_k > 0.7. We recommend calling 'loo' again with argument 'k_threshold = 0.7' in order to calculate the ELPD without the assumption that these observations are negligible. This will refit the model 1 times to compute the ELPDs for the problematic observations directly.\n```\n:::\n\n```{.r .cell-code}\n# Results\nc(loo_1$estimates[1], loo_2$estimates[1], \n  loo_3$estimates[1], loo_4$estimates[1])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] -568.4233 -625.7383 -461.0916 -457.6155\n```\n:::\n\n```{.r .cell-code}\n# Compare the ELPD for the 4 models\nloo_compare(loo_1, loo_2, loo_3, loo_4)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                elpd_diff se_diff\nweather_model_4    0.0       0.0 \nweather_model_3   -3.5       4.0 \nweather_model_1 -110.8      18.1 \nweather_model_2 -168.1      21.5 \n```\n:::\n:::\n\n\n## 11.5.4 The bias-variance trade-off\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Take 2 separate samples\nset.seed(84735)\nweather_shuffle <- weather_australia %>% \n  filter(temp3pm < 30, location == \"Wollongong\") %>% \n  sample_n(nrow(.))\nsample_1 <- weather_shuffle %>% head(40)\nsample_2 <- weather_shuffle %>% tail(40)\n\n# Save the plot for later\ng <- ggplot(sample_1, aes(y = temp3pm, x = day_of_year)) + \n  geom_point()\ng\n```\n\n::: {.cell-output-display}\n![](11_notes_files/figure-html/unnamed-chunk-21-1.png){width=672}\n:::\n\n```{.r .cell-code}\ng + geom_smooth(method = \"lm\", se = FALSE)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n`geom_smooth()` using formula = 'y ~ x'\n```\n:::\n\n::: {.cell-output-display}\n![](11_notes_files/figure-html/unnamed-chunk-21-2.png){width=672}\n:::\n\n```{.r .cell-code}\ng + stat_smooth(method = \"lm\", se = FALSE, formula = y ~ poly(x, 2))\n```\n\n::: {.cell-output-display}\n![](11_notes_files/figure-html/unnamed-chunk-21-3.png){width=672}\n:::\n\n```{.r .cell-code}\ng + stat_smooth(method = \"lm\", se = FALSE, formula = y ~ poly(x, 12))\n```\n\n::: {.cell-output-display}\n![](11_notes_files/figure-html/unnamed-chunk-21-4.png){width=672}\n:::\n:::\n\n::: {.cell hash='11_notes_cache/html/unnamed-chunk-22_017f51e41de7d3b58dbbba091a1b4cac'}\n\n```{.r .cell-code}\nmodel_1 <- stan_glm(\n  temp3pm ~ day_of_year,\n  data = sample_1, family = gaussian,\n  prior_intercept = normal(25, 5),\n  prior = normal(0, 2.5, autoscale = TRUE),\n  prior_aux = exponential(1, autoscale = TRUE),\n  chains = 4, iter = 5000*2, seed = 84735)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nSAMPLING FOR MODEL 'continuous' NOW (CHAIN 1).\nChain 1: \nChain 1: Gradient evaluation took 1.4e-05 seconds\nChain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.14 seconds.\nChain 1: Adjust your expectations accordingly!\nChain 1: \nChain 1: \nChain 1: Iteration:    1 / 10000 [  0%]  (Warmup)\nChain 1: Iteration: 1000 / 10000 [ 10%]  (Warmup)\nChain 1: Iteration: 2000 / 10000 [ 20%]  (Warmup)\nChain 1: Iteration: 3000 / 10000 [ 30%]  (Warmup)\nChain 1: Iteration: 4000 / 10000 [ 40%]  (Warmup)\nChain 1: Iteration: 5000 / 10000 [ 50%]  (Warmup)\nChain 1: Iteration: 5001 / 10000 [ 50%]  (Sampling)\nChain 1: Iteration: 6000 / 10000 [ 60%]  (Sampling)\nChain 1: Iteration: 7000 / 10000 [ 70%]  (Sampling)\nChain 1: Iteration: 8000 / 10000 [ 80%]  (Sampling)\nChain 1: Iteration: 9000 / 10000 [ 90%]  (Sampling)\nChain 1: Iteration: 10000 / 10000 [100%]  (Sampling)\nChain 1: \nChain 1:  Elapsed Time: 0.147 seconds (Warm-up)\nChain 1:                0.17 seconds (Sampling)\nChain 1:                0.317 seconds (Total)\nChain 1: \n\nSAMPLING FOR MODEL 'continuous' NOW (CHAIN 2).\nChain 2: \nChain 2: Gradient evaluation took 1.2e-05 seconds\nChain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.12 seconds.\nChain 2: Adjust your expectations accordingly!\nChain 2: \nChain 2: \nChain 2: Iteration:    1 / 10000 [  0%]  (Warmup)\nChain 2: Iteration: 1000 / 10000 [ 10%]  (Warmup)\nChain 2: Iteration: 2000 / 10000 [ 20%]  (Warmup)\nChain 2: Iteration: 3000 / 10000 [ 30%]  (Warmup)\nChain 2: Iteration: 4000 / 10000 [ 40%]  (Warmup)\nChain 2: Iteration: 5000 / 10000 [ 50%]  (Warmup)\nChain 2: Iteration: 5001 / 10000 [ 50%]  (Sampling)\nChain 2: Iteration: 6000 / 10000 [ 60%]  (Sampling)\nChain 2: Iteration: 7000 / 10000 [ 70%]  (Sampling)\nChain 2: Iteration: 8000 / 10000 [ 80%]  (Sampling)\nChain 2: Iteration: 9000 / 10000 [ 90%]  (Sampling)\nChain 2: Iteration: 10000 / 10000 [100%]  (Sampling)\nChain 2: \nChain 2:  Elapsed Time: 0.129 seconds (Warm-up)\nChain 2:                0.16 seconds (Sampling)\nChain 2:                0.289 seconds (Total)\nChain 2: \n\nSAMPLING FOR MODEL 'continuous' NOW (CHAIN 3).\nChain 3: \nChain 3: Gradient evaluation took 1e-05 seconds\nChain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.1 seconds.\nChain 3: Adjust your expectations accordingly!\nChain 3: \nChain 3: \nChain 3: Iteration:    1 / 10000 [  0%]  (Warmup)\nChain 3: Iteration: 1000 / 10000 [ 10%]  (Warmup)\nChain 3: Iteration: 2000 / 10000 [ 20%]  (Warmup)\nChain 3: Iteration: 3000 / 10000 [ 30%]  (Warmup)\nChain 3: Iteration: 4000 / 10000 [ 40%]  (Warmup)\nChain 3: Iteration: 5000 / 10000 [ 50%]  (Warmup)\nChain 3: Iteration: 5001 / 10000 [ 50%]  (Sampling)\nChain 3: Iteration: 6000 / 10000 [ 60%]  (Sampling)\nChain 3: Iteration: 7000 / 10000 [ 70%]  (Sampling)\nChain 3: Iteration: 8000 / 10000 [ 80%]  (Sampling)\nChain 3: Iteration: 9000 / 10000 [ 90%]  (Sampling)\nChain 3: Iteration: 10000 / 10000 [100%]  (Sampling)\nChain 3: \nChain 3:  Elapsed Time: 0.148 seconds (Warm-up)\nChain 3:                0.172 seconds (Sampling)\nChain 3:                0.32 seconds (Total)\nChain 3: \n\nSAMPLING FOR MODEL 'continuous' NOW (CHAIN 4).\nChain 4: \nChain 4: Gradient evaluation took 6e-06 seconds\nChain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.06 seconds.\nChain 4: Adjust your expectations accordingly!\nChain 4: \nChain 4: \nChain 4: Iteration:    1 / 10000 [  0%]  (Warmup)\nChain 4: Iteration: 1000 / 10000 [ 10%]  (Warmup)\nChain 4: Iteration: 2000 / 10000 [ 20%]  (Warmup)\nChain 4: Iteration: 3000 / 10000 [ 30%]  (Warmup)\nChain 4: Iteration: 4000 / 10000 [ 40%]  (Warmup)\nChain 4: Iteration: 5000 / 10000 [ 50%]  (Warmup)\nChain 4: Iteration: 5001 / 10000 [ 50%]  (Sampling)\nChain 4: Iteration: 6000 / 10000 [ 60%]  (Sampling)\nChain 4: Iteration: 7000 / 10000 [ 70%]  (Sampling)\nChain 4: Iteration: 8000 / 10000 [ 80%]  (Sampling)\nChain 4: Iteration: 9000 / 10000 [ 90%]  (Sampling)\nChain 4: Iteration: 10000 / 10000 [100%]  (Sampling)\nChain 4: \nChain 4:  Elapsed Time: 0.134 seconds (Warm-up)\nChain 4:                0.155 seconds (Sampling)\nChain 4:                0.289 seconds (Total)\nChain 4: \n```\n:::\n\n```{.r .cell-code}\n# Ditto the syntax for models 2 and 3\nmodel_2 <- stan_glm(temp3pm ~ poly(day_of_year, 2), \n                    data = sample_1, family = gaussian,\n                    prior_intercept = normal(25, 5),\n                    prior = normal(0, 2.5, autoscale = TRUE),\n                    prior_aux = exponential(1, autoscale = TRUE),\n                    chains = 4, iter = 5000*2, seed = 84735)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nSAMPLING FOR MODEL 'continuous' NOW (CHAIN 1).\nChain 1: \nChain 1: Gradient evaluation took 1.4e-05 seconds\nChain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.14 seconds.\nChain 1: Adjust your expectations accordingly!\nChain 1: \nChain 1: \nChain 1: Iteration:    1 / 10000 [  0%]  (Warmup)\nChain 1: Iteration: 1000 / 10000 [ 10%]  (Warmup)\nChain 1: Iteration: 2000 / 10000 [ 20%]  (Warmup)\nChain 1: Iteration: 3000 / 10000 [ 30%]  (Warmup)\nChain 1: Iteration: 4000 / 10000 [ 40%]  (Warmup)\nChain 1: Iteration: 5000 / 10000 [ 50%]  (Warmup)\nChain 1: Iteration: 5001 / 10000 [ 50%]  (Sampling)\nChain 1: Iteration: 6000 / 10000 [ 60%]  (Sampling)\nChain 1: Iteration: 7000 / 10000 [ 70%]  (Sampling)\nChain 1: Iteration: 8000 / 10000 [ 80%]  (Sampling)\nChain 1: Iteration: 9000 / 10000 [ 90%]  (Sampling)\nChain 1: Iteration: 10000 / 10000 [100%]  (Sampling)\nChain 1: \nChain 1:  Elapsed Time: 0.155 seconds (Warm-up)\nChain 1:                0.256 seconds (Sampling)\nChain 1:                0.411 seconds (Total)\nChain 1: \n\nSAMPLING FOR MODEL 'continuous' NOW (CHAIN 2).\nChain 2: \nChain 2: Gradient evaluation took 7e-06 seconds\nChain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.07 seconds.\nChain 2: Adjust your expectations accordingly!\nChain 2: \nChain 2: \nChain 2: Iteration:    1 / 10000 [  0%]  (Warmup)\nChain 2: Iteration: 1000 / 10000 [ 10%]  (Warmup)\nChain 2: Iteration: 2000 / 10000 [ 20%]  (Warmup)\nChain 2: Iteration: 3000 / 10000 [ 30%]  (Warmup)\nChain 2: Iteration: 4000 / 10000 [ 40%]  (Warmup)\nChain 2: Iteration: 5000 / 10000 [ 50%]  (Warmup)\nChain 2: Iteration: 5001 / 10000 [ 50%]  (Sampling)\nChain 2: Iteration: 6000 / 10000 [ 60%]  (Sampling)\nChain 2: Iteration: 7000 / 10000 [ 70%]  (Sampling)\nChain 2: Iteration: 8000 / 10000 [ 80%]  (Sampling)\nChain 2: Iteration: 9000 / 10000 [ 90%]  (Sampling)\nChain 2: Iteration: 10000 / 10000 [100%]  (Sampling)\nChain 2: \nChain 2:  Elapsed Time: 0.153 seconds (Warm-up)\nChain 2:                0.167 seconds (Sampling)\nChain 2:                0.32 seconds (Total)\nChain 2: \n\nSAMPLING FOR MODEL 'continuous' NOW (CHAIN 3).\nChain 3: \nChain 3: Gradient evaluation took 7e-06 seconds\nChain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.07 seconds.\nChain 3: Adjust your expectations accordingly!\nChain 3: \nChain 3: \nChain 3: Iteration:    1 / 10000 [  0%]  (Warmup)\nChain 3: Iteration: 1000 / 10000 [ 10%]  (Warmup)\nChain 3: Iteration: 2000 / 10000 [ 20%]  (Warmup)\nChain 3: Iteration: 3000 / 10000 [ 30%]  (Warmup)\nChain 3: Iteration: 4000 / 10000 [ 40%]  (Warmup)\nChain 3: Iteration: 5000 / 10000 [ 50%]  (Warmup)\nChain 3: Iteration: 5001 / 10000 [ 50%]  (Sampling)\nChain 3: Iteration: 6000 / 10000 [ 60%]  (Sampling)\nChain 3: Iteration: 7000 / 10000 [ 70%]  (Sampling)\nChain 3: Iteration: 8000 / 10000 [ 80%]  (Sampling)\nChain 3: Iteration: 9000 / 10000 [ 90%]  (Sampling)\nChain 3: Iteration: 10000 / 10000 [100%]  (Sampling)\nChain 3: \nChain 3:  Elapsed Time: 0.147 seconds (Warm-up)\nChain 3:                0.169 seconds (Sampling)\nChain 3:                0.316 seconds (Total)\nChain 3: \n\nSAMPLING FOR MODEL 'continuous' NOW (CHAIN 4).\nChain 4: \nChain 4: Gradient evaluation took 1.1e-05 seconds\nChain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.11 seconds.\nChain 4: Adjust your expectations accordingly!\nChain 4: \nChain 4: \nChain 4: Iteration:    1 / 10000 [  0%]  (Warmup)\nChain 4: Iteration: 1000 / 10000 [ 10%]  (Warmup)\nChain 4: Iteration: 2000 / 10000 [ 20%]  (Warmup)\nChain 4: Iteration: 3000 / 10000 [ 30%]  (Warmup)\nChain 4: Iteration: 4000 / 10000 [ 40%]  (Warmup)\nChain 4: Iteration: 5000 / 10000 [ 50%]  (Warmup)\nChain 4: Iteration: 5001 / 10000 [ 50%]  (Sampling)\nChain 4: Iteration: 6000 / 10000 [ 60%]  (Sampling)\nChain 4: Iteration: 7000 / 10000 [ 70%]  (Sampling)\nChain 4: Iteration: 8000 / 10000 [ 80%]  (Sampling)\nChain 4: Iteration: 9000 / 10000 [ 90%]  (Sampling)\nChain 4: Iteration: 10000 / 10000 [100%]  (Sampling)\nChain 4: \nChain 4:  Elapsed Time: 0.147 seconds (Warm-up)\nChain 4:                0.166 seconds (Sampling)\nChain 4:                0.313 seconds (Total)\nChain 4: \n```\n:::\n\n```{.r .cell-code}\nmodel_3 <- stan_glm(temp3pm ~ poly(day_of_year, 12),\n                    data = sample_1, family = gaussian,\n                    prior_intercept = normal(25, 5),\n                    prior = normal(0, 2.5, autoscale = TRUE),\n                    prior_aux = exponential(1, autoscale = TRUE),\n                    chains = 4, iter = 5000*2, seed = 84735)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nSAMPLING FOR MODEL 'continuous' NOW (CHAIN 1).\nChain 1: \nChain 1: Gradient evaluation took 1.6e-05 seconds\nChain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.16 seconds.\nChain 1: Adjust your expectations accordingly!\nChain 1: \nChain 1: \nChain 1: Iteration:    1 / 10000 [  0%]  (Warmup)\nChain 1: Iteration: 1000 / 10000 [ 10%]  (Warmup)\nChain 1: Iteration: 2000 / 10000 [ 20%]  (Warmup)\nChain 1: Iteration: 3000 / 10000 [ 30%]  (Warmup)\nChain 1: Iteration: 4000 / 10000 [ 40%]  (Warmup)\nChain 1: Iteration: 5000 / 10000 [ 50%]  (Warmup)\nChain 1: Iteration: 5001 / 10000 [ 50%]  (Sampling)\nChain 1: Iteration: 6000 / 10000 [ 60%]  (Sampling)\nChain 1: Iteration: 7000 / 10000 [ 70%]  (Sampling)\nChain 1: Iteration: 8000 / 10000 [ 80%]  (Sampling)\nChain 1: Iteration: 9000 / 10000 [ 90%]  (Sampling)\nChain 1: Iteration: 10000 / 10000 [100%]  (Sampling)\nChain 1: \nChain 1:  Elapsed Time: 0.28 seconds (Warm-up)\nChain 1:                0.37 seconds (Sampling)\nChain 1:                0.65 seconds (Total)\nChain 1: \n\nSAMPLING FOR MODEL 'continuous' NOW (CHAIN 2).\nChain 2: \nChain 2: Gradient evaluation took 9e-06 seconds\nChain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.09 seconds.\nChain 2: Adjust your expectations accordingly!\nChain 2: \nChain 2: \nChain 2: Iteration:    1 / 10000 [  0%]  (Warmup)\nChain 2: Iteration: 1000 / 10000 [ 10%]  (Warmup)\nChain 2: Iteration: 2000 / 10000 [ 20%]  (Warmup)\nChain 2: Iteration: 3000 / 10000 [ 30%]  (Warmup)\nChain 2: Iteration: 4000 / 10000 [ 40%]  (Warmup)\nChain 2: Iteration: 5000 / 10000 [ 50%]  (Warmup)\nChain 2: Iteration: 5001 / 10000 [ 50%]  (Sampling)\nChain 2: Iteration: 6000 / 10000 [ 60%]  (Sampling)\nChain 2: Iteration: 7000 / 10000 [ 70%]  (Sampling)\nChain 2: Iteration: 8000 / 10000 [ 80%]  (Sampling)\nChain 2: Iteration: 9000 / 10000 [ 90%]  (Sampling)\nChain 2: Iteration: 10000 / 10000 [100%]  (Sampling)\nChain 2: \nChain 2:  Elapsed Time: 0.278 seconds (Warm-up)\nChain 2:                0.299 seconds (Sampling)\nChain 2:                0.577 seconds (Total)\nChain 2: \n\nSAMPLING FOR MODEL 'continuous' NOW (CHAIN 3).\nChain 3: \nChain 3: Gradient evaluation took 1.2e-05 seconds\nChain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.12 seconds.\nChain 3: Adjust your expectations accordingly!\nChain 3: \nChain 3: \nChain 3: Iteration:    1 / 10000 [  0%]  (Warmup)\nChain 3: Iteration: 1000 / 10000 [ 10%]  (Warmup)\nChain 3: Iteration: 2000 / 10000 [ 20%]  (Warmup)\nChain 3: Iteration: 3000 / 10000 [ 30%]  (Warmup)\nChain 3: Iteration: 4000 / 10000 [ 40%]  (Warmup)\nChain 3: Iteration: 5000 / 10000 [ 50%]  (Warmup)\nChain 3: Iteration: 5001 / 10000 [ 50%]  (Sampling)\nChain 3: Iteration: 6000 / 10000 [ 60%]  (Sampling)\nChain 3: Iteration: 7000 / 10000 [ 70%]  (Sampling)\nChain 3: Iteration: 8000 / 10000 [ 80%]  (Sampling)\nChain 3: Iteration: 9000 / 10000 [ 90%]  (Sampling)\nChain 3: Iteration: 10000 / 10000 [100%]  (Sampling)\nChain 3: \nChain 3:  Elapsed Time: 0.257 seconds (Warm-up)\nChain 3:                0.349 seconds (Sampling)\nChain 3:                0.606 seconds (Total)\nChain 3: \n\nSAMPLING FOR MODEL 'continuous' NOW (CHAIN 4).\nChain 4: \nChain 4: Gradient evaluation took 9e-06 seconds\nChain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.09 seconds.\nChain 4: Adjust your expectations accordingly!\nChain 4: \nChain 4: \nChain 4: Iteration:    1 / 10000 [  0%]  (Warmup)\nChain 4: Iteration: 1000 / 10000 [ 10%]  (Warmup)\nChain 4: Iteration: 2000 / 10000 [ 20%]  (Warmup)\nChain 4: Iteration: 3000 / 10000 [ 30%]  (Warmup)\nChain 4: Iteration: 4000 / 10000 [ 40%]  (Warmup)\nChain 4: Iteration: 5000 / 10000 [ 50%]  (Warmup)\nChain 4: Iteration: 5001 / 10000 [ 50%]  (Sampling)\nChain 4: Iteration: 6000 / 10000 [ 60%]  (Sampling)\nChain 4: Iteration: 7000 / 10000 [ 70%]  (Sampling)\nChain 4: Iteration: 8000 / 10000 [ 80%]  (Sampling)\nChain 4: Iteration: 9000 / 10000 [ 90%]  (Sampling)\nChain 4: Iteration: 10000 / 10000 [100%]  (Sampling)\nChain 4: \nChain 4:  Elapsed Time: 0.273 seconds (Warm-up)\nChain 4:                0.33 seconds (Sampling)\nChain 4:                0.603 seconds (Total)\nChain 4: \n```\n:::\n\n```{.r .cell-code}\nset.seed(84735)\nprediction_summary(model = model_1, data = sample_1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n       mae mae_scaled within_50 within_95\n1 2.788129   0.819851     0.475         1\n```\n:::\n\n```{.r .cell-code}\nprediction_summary_cv(model = model_1, data = sample_1, k = 10)$cv\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n      mae mae_scaled within_50 within_95\n1 2.82925  0.8308622     0.475     0.975\n```\n:::\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}