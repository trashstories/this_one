{
  "hash": "8c1bf75332eec821f0be6a8280e027ed",
  "result": {
    "markdown": "---\ntitle: \"10: Evaluating Regression Models\"\neditor_options: \n  chunk_output_type: console\n---\n\n::: {.cell}\n\n```{.r .cell-code}\n# Load packages\nlibrary(bayesrules)\nlibrary(tidyverse)\nlibrary(bayesplot)\nlibrary(rstanarm)\n\nbike_model <- readRDS(\"bike_model.RDS\")\nbike_model_df <- readRDS(\"bike_model_df.RDS\")\n```\n:::\n\n\n# 10.2.1 Checking the model assumptions\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(bikes, aes(y = rides, x = temp_feel)) + \n  geom_point(size = 1) + \n  geom_smooth(method = \"lm\", se = FALSE)\n```\n\n::: {.cell-output-display}\n![](10_notes_files/figure-html/unnamed-chunk-2-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nfirst_set <- head(bike_model_df, 1)\nfirst_set\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  (Intercept) temp_feel    sigma\n1   -2593.578  87.59029 1362.773\n```\n:::\n\n```{.r .cell-code}\nbeta_0 <- first_set$`(Intercept)`\nbeta_1 <- first_set$temp_feel\nsigma  <- first_set$sigma\n\nset.seed(84735)\none_simulation <- bikes %>% \n  mutate(mu = beta_0 + beta_1 * temp_feel,\n         simulated_rides = rnorm(500, mean = mu, sd = sigma)) %>% \n  select(temp_feel, rides, simulated_rides)\n\nhead(one_simulation, 2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  temp_feel rides simulated_rides\n1  64.72625   654        3985.100\n2  49.04645  1229        1533.649\n```\n:::\n\n```{.r .cell-code}\nggplot(one_simulation, aes(x = simulated_rides)) + \n  geom_density(color = \"lightblue\") + \n  geom_density(aes(x = rides), color = \"darkblue\")\n```\n\n::: {.cell-output-display}\n![](10_notes_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n\n```{.r .cell-code}\n# Examine 50 of the 20000 simulated samples\npp_check(bike_model, nreps = 50) + \n  xlab(\"rides\")\n```\n\n::: {.cell-output-display}\n![](10_notes_files/figure-html/unnamed-chunk-3-2.png){width=672}\n:::\n:::\n\n\n# 10.3 How accurate are the posterior predictive models?\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbikes %>% \n  filter(date == \"2012-10-22\") %>% \n  select(temp_feel, rides)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  temp_feel rides\n1  75.46478  6228\n```\n:::\n\n```{.r .cell-code}\n# Simulate the posterior predictive model\nset.seed(84735)\npredict_75 <- bike_model_df %>% \n  mutate(mu = `(Intercept)` + temp_feel*75,\n         y_new = rnorm(20000, mean = mu, sd = sigma))\n\n# Plot the posterior predictive model\nggplot(predict_75, aes(x = y_new)) + \n  geom_density()\n```\n\n::: {.cell-output-display}\n![](10_notes_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n\n```{.r .cell-code}\npredict_75 %>% \n  summarize(mean = mean(y_new), error = 6228 - mean(y_new))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n    mean  error\n1 3966.3 2261.7\n```\n:::\n\n```{.r .cell-code}\npredict_75 %>% \n  summarize(sd = sd(y_new), error = 6228 - mean(y_new),\n            error_scaled = error / sd(y_new))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n        sd  error error_scaled\n1 1281.188 2261.7     1.765314\n```\n:::\n\n```{.r .cell-code}\npredict_75 %>% \n  summarize(lower_95 = quantile(y_new, 0.025),\n            lower_50 = quantile(y_new, 0.25),\n            upper_50 = quantile(y_new, 0.75),\n            upper_95 = quantile(y_new, 0.975))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  lower_95 lower_50 upper_50 upper_95\n1 1492.104 3094.158  4827.83 6488.281\n```\n:::\n\n```{.r .cell-code}\nset.seed(84735)\npredictions <- posterior_predict(bike_model, newdata = bikes)\ndim(predictions)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 20000   500\n```\n:::\n\n```{.r .cell-code}\nppc_intervals(bikes$rides, yrep = predictions, x = bikes$temp_feel, \n              prob = 0.5, prob_outer = 0.95)\n```\n\n::: {.cell-output-display}\n![](10_notes_files/figure-html/unnamed-chunk-4-2.png){width=672}\n:::\n\n```{.r .cell-code}\n# Posterior predictive summaries\nset.seed(84735)\nprediction_summary(bike_model, data = bikes)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n       mae mae_scaled within_50 within_95\n1 991.8959  0.7710714     0.438     0.968\n```\n:::\n:::\n\n\n# 10.3.2 Cross-validation\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(84735)\ncv_procedure <- prediction_summary_cv(\n  model = bike_model, data = bikes, k = 10)\n\ncv_procedure$folds\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   fold       mae mae_scaled within_50 within_95\n1     1  990.3608  0.7702115      0.46      0.98\n2     2  966.9762  0.7455495      0.42      1.00\n3     3  950.9552  0.7306885      0.42      0.98\n4     4 1018.0607  0.7912895      0.46      0.98\n5     5 1161.3059  0.9085343      0.36      0.96\n6     6  937.2161  0.7320193      0.46      0.94\n7     7 1270.4691  1.0059101      0.32      0.96\n8     8 1111.9435  0.8605897      0.36      1.00\n9     9 1099.6156  0.8683029      0.40      0.92\n10   10  786.6133  0.6067533      0.56      0.94\n```\n:::\n\n```{.r .cell-code}\ncv_procedure$cv\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n       mae mae_scaled within_50 within_95\n1 1029.352  0.8019849     0.422     0.966\n```\n:::\n\n```{.r .cell-code}\n# Posterior predictive summaries for original data\nset.seed(84735)\nprediction_summary(bike_model, data = bikes)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n       mae mae_scaled within_50 within_95\n1 991.8959  0.7710714     0.438     0.968\n```\n:::\n:::\n\n\n# 10.3.3 Expected log-predictive density\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel_elpd <- loo(bike_model)\nmodel_elpd$estimates\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n             Estimate         SE\nelpd_loo -4288.998197 13.1166003\np_loo        2.466119  0.1620926\nlooic     8577.996395 26.2332007\n```\n:::\n:::\n",
    "supporting": [
      "10_notes_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}