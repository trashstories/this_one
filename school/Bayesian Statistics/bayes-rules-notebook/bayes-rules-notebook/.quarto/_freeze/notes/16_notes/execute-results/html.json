{
  "hash": "a20dfafc580074c040fdc70726e19c91",
  "result": {
    "markdown": "---\ntitle: \"16: (Normal) Hierarchical Models without Predictors\"\neditor_options: \n  chunk_output_type: console\n---\n\n::: {.cell}\n\n```{.r .cell-code}\n# Load packages\nlibrary(bayesrules)\nlibrary(tidyverse)\nlibrary(rstanarm)\nlibrary(bayesplot)\nlibrary(tidybayes)\nlibrary(broom.mixed)\nlibrary(forcats)\n\n# Load data\ndata(spotify)\n\nspotify <- spotify %>% \n  select(artist, title, popularity) %>% \n  mutate(artist = fct_reorder(artist, popularity, .fun = 'mean'))\n\n# First few rows\nhead(spotify, 3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 3 × 3\n  artist title        popularity\n  <fct>  <chr>             <dbl>\n1 Alok   On & On              79\n2 Alok   All The Lies         56\n3 Alok   Hear Me Now          75\n```\n:::\n\n```{.r .cell-code}\n# Number of songs\nnrow(spotify)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 350\n```\n:::\n\n```{.r .cell-code}\n# Number of artists\nnlevels(spotify$artist)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 44\n```\n:::\n\n```{.r .cell-code}\nartist_means <- spotify %>% \n  group_by(artist) %>% \n  summarize(count = n(), popularity = mean(popularity))\n\nartist_means %>%\n  slice(1:2, 43:44)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 4 × 3\n  artist        count popularity\n  <fct>         <int>      <dbl>\n1 Mia X             4       13.2\n2 Chris Goldarg    10       16.4\n3 Lil Skies         3       79.3\n4 Camilo            9       81  \n```\n:::\n:::\n\n\n# 16.1 Complete pooled model\n\n\n::: {.cell hash='16_notes_cache/html/unnamed-chunk-2_431b9ad90d57791221fa28a9e5fe4554'}\n\n```{.r .cell-code}\nhead(artist_means, 2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2 × 3\n  artist        count popularity\n  <fct>         <int>      <dbl>\n1 Mia X             4       13.2\n2 Chris Goldarg    10       16.4\n```\n:::\n\n```{.r .cell-code}\nartist_means %>% \n  summarize(min(count), max(count))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 × 2\n  `min(count)` `max(count)`\n         <int>        <int>\n1            2           40\n```\n:::\n\n```{.r .cell-code}\nggplot(spotify, aes(x = popularity)) + \n  geom_density()\n```\n\n::: {.cell-output-display}\n![](16_notes_files/figure-html/unnamed-chunk-2-1.png){width=672}\n:::\n\n```{.r .cell-code}\nspotify_complete_pooled <- stan_glm(\n  popularity ~ 1, \n  data = spotify, family = gaussian, \n  prior_intercept = normal(50, 2.5, autoscale = TRUE),\n  prior_aux = exponential(1, autoscale = TRUE),\n  chains = 4, iter = 5000*2, seed = 84735)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nSAMPLING FOR MODEL 'continuous' NOW (CHAIN 1).\nChain 1: \nChain 1: Gradient evaluation took 4.4e-05 seconds\nChain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.44 seconds.\nChain 1: Adjust your expectations accordingly!\nChain 1: \nChain 1: \nChain 1: Iteration:    1 / 10000 [  0%]  (Warmup)\nChain 1: Iteration: 1000 / 10000 [ 10%]  (Warmup)\nChain 1: Iteration: 2000 / 10000 [ 20%]  (Warmup)\nChain 1: Iteration: 3000 / 10000 [ 30%]  (Warmup)\nChain 1: Iteration: 4000 / 10000 [ 40%]  (Warmup)\nChain 1: Iteration: 5000 / 10000 [ 50%]  (Warmup)\nChain 1: Iteration: 5001 / 10000 [ 50%]  (Sampling)\nChain 1: Iteration: 6000 / 10000 [ 60%]  (Sampling)\nChain 1: Iteration: 7000 / 10000 [ 70%]  (Sampling)\nChain 1: Iteration: 8000 / 10000 [ 80%]  (Sampling)\nChain 1: Iteration: 9000 / 10000 [ 90%]  (Sampling)\nChain 1: Iteration: 10000 / 10000 [100%]  (Sampling)\nChain 1: \nChain 1:  Elapsed Time: 0.123 seconds (Warm-up)\nChain 1:                0.264 seconds (Sampling)\nChain 1:                0.387 seconds (Total)\nChain 1: \n\nSAMPLING FOR MODEL 'continuous' NOW (CHAIN 2).\nChain 2: \nChain 2: Gradient evaluation took 1.5e-05 seconds\nChain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.15 seconds.\nChain 2: Adjust your expectations accordingly!\nChain 2: \nChain 2: \nChain 2: Iteration:    1 / 10000 [  0%]  (Warmup)\nChain 2: Iteration: 1000 / 10000 [ 10%]  (Warmup)\nChain 2: Iteration: 2000 / 10000 [ 20%]  (Warmup)\nChain 2: Iteration: 3000 / 10000 [ 30%]  (Warmup)\nChain 2: Iteration: 4000 / 10000 [ 40%]  (Warmup)\nChain 2: Iteration: 5000 / 10000 [ 50%]  (Warmup)\nChain 2: Iteration: 5001 / 10000 [ 50%]  (Sampling)\nChain 2: Iteration: 6000 / 10000 [ 60%]  (Sampling)\nChain 2: Iteration: 7000 / 10000 [ 70%]  (Sampling)\nChain 2: Iteration: 8000 / 10000 [ 80%]  (Sampling)\nChain 2: Iteration: 9000 / 10000 [ 90%]  (Sampling)\nChain 2: Iteration: 10000 / 10000 [100%]  (Sampling)\nChain 2: \nChain 2:  Elapsed Time: 0.152 seconds (Warm-up)\nChain 2:                0.286 seconds (Sampling)\nChain 2:                0.438 seconds (Total)\nChain 2: \n\nSAMPLING FOR MODEL 'continuous' NOW (CHAIN 3).\nChain 3: \nChain 3: Gradient evaluation took 9e-06 seconds\nChain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.09 seconds.\nChain 3: Adjust your expectations accordingly!\nChain 3: \nChain 3: \nChain 3: Iteration:    1 / 10000 [  0%]  (Warmup)\nChain 3: Iteration: 1000 / 10000 [ 10%]  (Warmup)\nChain 3: Iteration: 2000 / 10000 [ 20%]  (Warmup)\nChain 3: Iteration: 3000 / 10000 [ 30%]  (Warmup)\nChain 3: Iteration: 4000 / 10000 [ 40%]  (Warmup)\nChain 3: Iteration: 5000 / 10000 [ 50%]  (Warmup)\nChain 3: Iteration: 5001 / 10000 [ 50%]  (Sampling)\nChain 3: Iteration: 6000 / 10000 [ 60%]  (Sampling)\nChain 3: Iteration: 7000 / 10000 [ 70%]  (Sampling)\nChain 3: Iteration: 8000 / 10000 [ 80%]  (Sampling)\nChain 3: Iteration: 9000 / 10000 [ 90%]  (Sampling)\nChain 3: Iteration: 10000 / 10000 [100%]  (Sampling)\nChain 3: \nChain 3:  Elapsed Time: 0.136 seconds (Warm-up)\nChain 3:                0.252 seconds (Sampling)\nChain 3:                0.388 seconds (Total)\nChain 3: \n\nSAMPLING FOR MODEL 'continuous' NOW (CHAIN 4).\nChain 4: \nChain 4: Gradient evaluation took 1.1e-05 seconds\nChain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.11 seconds.\nChain 4: Adjust your expectations accordingly!\nChain 4: \nChain 4: \nChain 4: Iteration:    1 / 10000 [  0%]  (Warmup)\nChain 4: Iteration: 1000 / 10000 [ 10%]  (Warmup)\nChain 4: Iteration: 2000 / 10000 [ 20%]  (Warmup)\nChain 4: Iteration: 3000 / 10000 [ 30%]  (Warmup)\nChain 4: Iteration: 4000 / 10000 [ 40%]  (Warmup)\nChain 4: Iteration: 5000 / 10000 [ 50%]  (Warmup)\nChain 4: Iteration: 5001 / 10000 [ 50%]  (Sampling)\nChain 4: Iteration: 6000 / 10000 [ 60%]  (Sampling)\nChain 4: Iteration: 7000 / 10000 [ 70%]  (Sampling)\nChain 4: Iteration: 8000 / 10000 [ 80%]  (Sampling)\nChain 4: Iteration: 9000 / 10000 [ 90%]  (Sampling)\nChain 4: Iteration: 10000 / 10000 [100%]  (Sampling)\nChain 4: \nChain 4:  Elapsed Time: 0.124 seconds (Warm-up)\nChain 4:                0.27 seconds (Sampling)\nChain 4:                0.394 seconds (Total)\nChain 4: \n```\n:::\n\n```{.r .cell-code}\n# Get prior specifications\nprior_summary(spotify_complete_pooled)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nPriors for model 'spotify_complete_pooled' \n------\nIntercept (after predictors centered)\n  Specified prior:\n    ~ normal(location = 50, scale = 2.5)\n  Adjusted prior:\n    ~ normal(location = 50, scale = 52)\n\nAuxiliary (sigma)\n  Specified prior:\n    ~ exponential(rate = 1)\n  Adjusted prior:\n    ~ exponential(rate = 0.048)\n------\nSee help('prior_summary.stanreg') for more details\n```\n:::\n\n```{.r .cell-code}\ncomplete_summary <- tidy(spotify_complete_pooled, \n                         effects = c(\"fixed\", \"aux\"), \n                         conf.int = TRUE, conf.level = 0.80)\ncomplete_summary\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 3 × 5\n  term        estimate std.error conf.low conf.high\n  <chr>          <dbl>     <dbl>    <dbl>     <dbl>\n1 (Intercept)     58.4     1.10      57.0      59.8\n2 sigma           20.7     0.776     19.7      21.7\n3 mean_PPD        58.4     1.57      56.4      60.4\n```\n:::\n\n```{.r .cell-code}\nset.seed(84735)\npredictions_complete <- posterior_predict(spotify_complete_pooled,\n                                          newdata = artist_means)\n\nppc_intervals(artist_means$popularity, yrep = predictions_complete,\n              prob_outer = 0.80) +\n  ggplot2::scale_x_continuous(labels = artist_means$artist,\n                              breaks = 1:nrow(artist_means)) +\n  xaxis_text(angle = 90, hjust = 1)\n```\n\n::: {.cell-output-display}\n![](16_notes_files/figure-html/unnamed-chunk-2-2.png){width=672}\n:::\n:::\n\n\n# 16.2 No pooled model\n\n\n::: {.cell hash='16_notes_cache/html/unnamed-chunk-3_b7de603626af575baf05d92c3a81c894'}\n\n```{.r .cell-code}\nggplot(spotify, aes(x = popularity, group = artist)) + \n  geom_density()\n```\n\n::: {.cell-output-display}\n![](16_notes_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n\n```{.r .cell-code}\nspotify_no_pooled <- stan_glm(\n  popularity ~ artist - 1, \n  data = spotify, family = gaussian, \n  prior = normal(50, 2.5, autoscale = TRUE),\n  prior_aux = exponential(1, autoscale = TRUE),\n  chains = 4, iter = 5000*2, seed = 84735)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nSAMPLING FOR MODEL 'continuous' NOW (CHAIN 1).\nChain 1: \nChain 1: Gradient evaluation took 2.3e-05 seconds\nChain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.23 seconds.\nChain 1: Adjust your expectations accordingly!\nChain 1: \nChain 1: \nChain 1: Iteration:    1 / 10000 [  0%]  (Warmup)\nChain 1: Iteration: 1000 / 10000 [ 10%]  (Warmup)\nChain 1: Iteration: 2000 / 10000 [ 20%]  (Warmup)\nChain 1: Iteration: 3000 / 10000 [ 30%]  (Warmup)\nChain 1: Iteration: 4000 / 10000 [ 40%]  (Warmup)\nChain 1: Iteration: 5000 / 10000 [ 50%]  (Warmup)\nChain 1: Iteration: 5001 / 10000 [ 50%]  (Sampling)\nChain 1: Iteration: 6000 / 10000 [ 60%]  (Sampling)\nChain 1: Iteration: 7000 / 10000 [ 70%]  (Sampling)\nChain 1: Iteration: 8000 / 10000 [ 80%]  (Sampling)\nChain 1: Iteration: 9000 / 10000 [ 90%]  (Sampling)\nChain 1: Iteration: 10000 / 10000 [100%]  (Sampling)\nChain 1: \nChain 1:  Elapsed Time: 0.668 seconds (Warm-up)\nChain 1:                0.868 seconds (Sampling)\nChain 1:                1.536 seconds (Total)\nChain 1: \n\nSAMPLING FOR MODEL 'continuous' NOW (CHAIN 2).\nChain 2: \nChain 2: Gradient evaluation took 2.5e-05 seconds\nChain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.25 seconds.\nChain 2: Adjust your expectations accordingly!\nChain 2: \nChain 2: \nChain 2: Iteration:    1 / 10000 [  0%]  (Warmup)\nChain 2: Iteration: 1000 / 10000 [ 10%]  (Warmup)\nChain 2: Iteration: 2000 / 10000 [ 20%]  (Warmup)\nChain 2: Iteration: 3000 / 10000 [ 30%]  (Warmup)\nChain 2: Iteration: 4000 / 10000 [ 40%]  (Warmup)\nChain 2: Iteration: 5000 / 10000 [ 50%]  (Warmup)\nChain 2: Iteration: 5001 / 10000 [ 50%]  (Sampling)\nChain 2: Iteration: 6000 / 10000 [ 60%]  (Sampling)\nChain 2: Iteration: 7000 / 10000 [ 70%]  (Sampling)\nChain 2: Iteration: 8000 / 10000 [ 80%]  (Sampling)\nChain 2: Iteration: 9000 / 10000 [ 90%]  (Sampling)\nChain 2: Iteration: 10000 / 10000 [100%]  (Sampling)\nChain 2: \nChain 2:  Elapsed Time: 0.64 seconds (Warm-up)\nChain 2:                0.835 seconds (Sampling)\nChain 2:                1.475 seconds (Total)\nChain 2: \n\nSAMPLING FOR MODEL 'continuous' NOW (CHAIN 3).\nChain 3: \nChain 3: Gradient evaluation took 1.1e-05 seconds\nChain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.11 seconds.\nChain 3: Adjust your expectations accordingly!\nChain 3: \nChain 3: \nChain 3: Iteration:    1 / 10000 [  0%]  (Warmup)\nChain 3: Iteration: 1000 / 10000 [ 10%]  (Warmup)\nChain 3: Iteration: 2000 / 10000 [ 20%]  (Warmup)\nChain 3: Iteration: 3000 / 10000 [ 30%]  (Warmup)\nChain 3: Iteration: 4000 / 10000 [ 40%]  (Warmup)\nChain 3: Iteration: 5000 / 10000 [ 50%]  (Warmup)\nChain 3: Iteration: 5001 / 10000 [ 50%]  (Sampling)\nChain 3: Iteration: 6000 / 10000 [ 60%]  (Sampling)\nChain 3: Iteration: 7000 / 10000 [ 70%]  (Sampling)\nChain 3: Iteration: 8000 / 10000 [ 80%]  (Sampling)\nChain 3: Iteration: 9000 / 10000 [ 90%]  (Sampling)\nChain 3: Iteration: 10000 / 10000 [100%]  (Sampling)\nChain 3: \nChain 3:  Elapsed Time: 0.664 seconds (Warm-up)\nChain 3:                0.839 seconds (Sampling)\nChain 3:                1.503 seconds (Total)\nChain 3: \n\nSAMPLING FOR MODEL 'continuous' NOW (CHAIN 4).\nChain 4: \nChain 4: Gradient evaluation took 1.4e-05 seconds\nChain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.14 seconds.\nChain 4: Adjust your expectations accordingly!\nChain 4: \nChain 4: \nChain 4: Iteration:    1 / 10000 [  0%]  (Warmup)\nChain 4: Iteration: 1000 / 10000 [ 10%]  (Warmup)\nChain 4: Iteration: 2000 / 10000 [ 20%]  (Warmup)\nChain 4: Iteration: 3000 / 10000 [ 30%]  (Warmup)\nChain 4: Iteration: 4000 / 10000 [ 40%]  (Warmup)\nChain 4: Iteration: 5000 / 10000 [ 50%]  (Warmup)\nChain 4: Iteration: 5001 / 10000 [ 50%]  (Sampling)\nChain 4: Iteration: 6000 / 10000 [ 60%]  (Sampling)\nChain 4: Iteration: 7000 / 10000 [ 70%]  (Sampling)\nChain 4: Iteration: 8000 / 10000 [ 80%]  (Sampling)\nChain 4: Iteration: 9000 / 10000 [ 90%]  (Sampling)\nChain 4: Iteration: 10000 / 10000 [100%]  (Sampling)\nChain 4: \nChain 4:  Elapsed Time: 0.645 seconds (Warm-up)\nChain 4:                0.851 seconds (Sampling)\nChain 4:                1.496 seconds (Total)\nChain 4: \n```\n:::\n\n```{.r .cell-code}\n# Simulate the posterior predictive models\nset.seed(84735)\npredictions_no <- posterior_predict(\n  spotify_no_pooled, newdata = artist_means)\n  \n# Plot the posterior predictive intervals\nppc_intervals(artist_means$popularity, yrep = predictions_no, \n              prob_outer = 0.80) +\n  ggplot2::scale_x_continuous(labels = artist_means$artist, \n                              breaks = 1:nrow(artist_means)) +\n  xaxis_text(angle = 90, hjust = 1)\n```\n\n::: {.cell-output-display}\n![](16_notes_files/figure-html/unnamed-chunk-3-2.png){width=672}\n:::\n:::\n\n\n# 16.3 Building the hierarchical model\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(artist_means, aes(x = popularity)) + \n  geom_density()\n```\n\n::: {.cell-output-display}\n![](16_notes_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n:::\n\n\n# 16.4 Posterior analysis\n\n\n::: {.cell hash='16_notes_cache/html/unnamed-chunk-5_cae90f5168303ad51eeaaa529d624326'}\n\n```{.r .cell-code}\nspotify_hierarchical <- stan_glmer(\n  popularity ~ (1 | artist), \n  data = spotify, family = gaussian,\n  prior_intercept = normal(50, 2.5, autoscale = TRUE),\n  prior_aux = exponential(1, autoscale = TRUE),\n  prior_covariance = decov(reg = 1, conc = 1, shape = 1, scale = 1),\n  chains = 4, iter = 5000*2, seed = 84735)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nSAMPLING FOR MODEL 'continuous' NOW (CHAIN 1).\nChain 1: \nChain 1: Gradient evaluation took 3.6e-05 seconds\nChain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.36 seconds.\nChain 1: Adjust your expectations accordingly!\nChain 1: \nChain 1: \nChain 1: Iteration:    1 / 10000 [  0%]  (Warmup)\nChain 1: Iteration: 1000 / 10000 [ 10%]  (Warmup)\nChain 1: Iteration: 2000 / 10000 [ 20%]  (Warmup)\nChain 1: Iteration: 3000 / 10000 [ 30%]  (Warmup)\nChain 1: Iteration: 4000 / 10000 [ 40%]  (Warmup)\nChain 1: Iteration: 5000 / 10000 [ 50%]  (Warmup)\nChain 1: Iteration: 5001 / 10000 [ 50%]  (Sampling)\nChain 1: Iteration: 6000 / 10000 [ 60%]  (Sampling)\nChain 1: Iteration: 7000 / 10000 [ 70%]  (Sampling)\nChain 1: Iteration: 8000 / 10000 [ 80%]  (Sampling)\nChain 1: Iteration: 9000 / 10000 [ 90%]  (Sampling)\nChain 1: Iteration: 10000 / 10000 [100%]  (Sampling)\nChain 1: \nChain 1:  Elapsed Time: 1.732 seconds (Warm-up)\nChain 1:                2.113 seconds (Sampling)\nChain 1:                3.845 seconds (Total)\nChain 1: \n\nSAMPLING FOR MODEL 'continuous' NOW (CHAIN 2).\nChain 2: \nChain 2: Gradient evaluation took 2.7e-05 seconds\nChain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.27 seconds.\nChain 2: Adjust your expectations accordingly!\nChain 2: \nChain 2: \nChain 2: Iteration:    1 / 10000 [  0%]  (Warmup)\nChain 2: Iteration: 1000 / 10000 [ 10%]  (Warmup)\nChain 2: Iteration: 2000 / 10000 [ 20%]  (Warmup)\nChain 2: Iteration: 3000 / 10000 [ 30%]  (Warmup)\nChain 2: Iteration: 4000 / 10000 [ 40%]  (Warmup)\nChain 2: Iteration: 5000 / 10000 [ 50%]  (Warmup)\nChain 2: Iteration: 5001 / 10000 [ 50%]  (Sampling)\nChain 2: Iteration: 6000 / 10000 [ 60%]  (Sampling)\nChain 2: Iteration: 7000 / 10000 [ 70%]  (Sampling)\nChain 2: Iteration: 8000 / 10000 [ 80%]  (Sampling)\nChain 2: Iteration: 9000 / 10000 [ 90%]  (Sampling)\nChain 2: Iteration: 10000 / 10000 [100%]  (Sampling)\nChain 2: \nChain 2:  Elapsed Time: 1.846 seconds (Warm-up)\nChain 2:                1.519 seconds (Sampling)\nChain 2:                3.365 seconds (Total)\nChain 2: \n\nSAMPLING FOR MODEL 'continuous' NOW (CHAIN 3).\nChain 3: \nChain 3: Gradient evaluation took 2.7e-05 seconds\nChain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.27 seconds.\nChain 3: Adjust your expectations accordingly!\nChain 3: \nChain 3: \nChain 3: Iteration:    1 / 10000 [  0%]  (Warmup)\nChain 3: Iteration: 1000 / 10000 [ 10%]  (Warmup)\nChain 3: Iteration: 2000 / 10000 [ 20%]  (Warmup)\nChain 3: Iteration: 3000 / 10000 [ 30%]  (Warmup)\nChain 3: Iteration: 4000 / 10000 [ 40%]  (Warmup)\nChain 3: Iteration: 5000 / 10000 [ 50%]  (Warmup)\nChain 3: Iteration: 5001 / 10000 [ 50%]  (Sampling)\nChain 3: Iteration: 6000 / 10000 [ 60%]  (Sampling)\nChain 3: Iteration: 7000 / 10000 [ 70%]  (Sampling)\nChain 3: Iteration: 8000 / 10000 [ 80%]  (Sampling)\nChain 3: Iteration: 9000 / 10000 [ 90%]  (Sampling)\nChain 3: Iteration: 10000 / 10000 [100%]  (Sampling)\nChain 3: \nChain 3:  Elapsed Time: 1.653 seconds (Warm-up)\nChain 3:                1.537 seconds (Sampling)\nChain 3:                3.19 seconds (Total)\nChain 3: \n\nSAMPLING FOR MODEL 'continuous' NOW (CHAIN 4).\nChain 4: \nChain 4: Gradient evaluation took 4.2e-05 seconds\nChain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.42 seconds.\nChain 4: Adjust your expectations accordingly!\nChain 4: \nChain 4: \nChain 4: Iteration:    1 / 10000 [  0%]  (Warmup)\nChain 4: Iteration: 1000 / 10000 [ 10%]  (Warmup)\nChain 4: Iteration: 2000 / 10000 [ 20%]  (Warmup)\nChain 4: Iteration: 3000 / 10000 [ 30%]  (Warmup)\nChain 4: Iteration: 4000 / 10000 [ 40%]  (Warmup)\nChain 4: Iteration: 5000 / 10000 [ 50%]  (Warmup)\nChain 4: Iteration: 5001 / 10000 [ 50%]  (Sampling)\nChain 4: Iteration: 6000 / 10000 [ 60%]  (Sampling)\nChain 4: Iteration: 7000 / 10000 [ 70%]  (Sampling)\nChain 4: Iteration: 8000 / 10000 [ 80%]  (Sampling)\nChain 4: Iteration: 9000 / 10000 [ 90%]  (Sampling)\nChain 4: Iteration: 10000 / 10000 [100%]  (Sampling)\nChain 4: \nChain 4:  Elapsed Time: 1.55 seconds (Warm-up)\nChain 4:                1.376 seconds (Sampling)\nChain 4:                2.926 seconds (Total)\nChain 4: \n```\n:::\n\n```{.r .cell-code}\n# Confirm the prior tunings\nprior_summary(spotify_hierarchical)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nPriors for model 'spotify_hierarchical' \n------\nIntercept (after predictors centered)\n  Specified prior:\n    ~ normal(location = 50, scale = 2.5)\n  Adjusted prior:\n    ~ normal(location = 50, scale = 52)\n\nAuxiliary (sigma)\n  Specified prior:\n    ~ exponential(rate = 1)\n  Adjusted prior:\n    ~ exponential(rate = 0.048)\n\nCovariance\n ~ decov(reg. = 1, conc. = 1, shape = 1, scale = 1)\n------\nSee help('prior_summary.stanreg') for more details\n```\n:::\n\n```{.r .cell-code}\nmcmc_trace(spotify_hierarchical)\n```\n\n::: {.cell-output-display}\n![](16_notes_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n\n```{.r .cell-code}\nmcmc_dens_overlay(spotify_hierarchical)\n```\n\n::: {.cell-output-display}\n![](16_notes_files/figure-html/unnamed-chunk-5-2.png){width=672}\n:::\n\n```{.r .cell-code}\nmcmc_acf(spotify_hierarchical)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: The `facets` argument of `facet_grid()` is deprecated as of ggplot2 2.2.0.\nℹ Please use the `rows` argument instead.\nℹ The deprecated feature was likely used in the bayesplot package.\n  Please report the issue at <https://github.com/stan-dev/bayesplot/issues/>.\n```\n:::\n\n::: {.cell-output-display}\n![](16_notes_files/figure-html/unnamed-chunk-5-3.png){width=672}\n:::\n\n```{.r .cell-code}\nneff_ratio(spotify_hierarchical)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                             (Intercept) \n                                 0.15425 \n             b[(Intercept) artist:Mia_X] \n                                 0.64145 \n     b[(Intercept) artist:Chris_Goldarg] \n                                 0.49470 \n         b[(Intercept) artist:Soul&Roll] \n                                 0.63425 \n        b[(Intercept) artist:Honeywagon] \n                                 0.85465 \n          b[(Intercept) artist:Röyksopp] \n                                 0.67445 \n         b[(Intercept) artist:Freestyle] \n                                 0.81670 \n          b[(Intercept) artist:DA_Image] \n                                 0.75810 \n         b[(Intercept) artist:Jean_Juan] \n                                 0.61935 \n          b[(Intercept) artist:TV_Noise] \n                                 0.39160 \n         b[(Intercept) artist:Kid_Frost] \n                                 0.77780 \n     b[(Intercept) artist:Tamar_Braxton] \n                                 0.82235 \n             b[(Intercept) artist:BUNT.] \n                                 0.84730 \n               b[(Intercept) artist:MTK] \n                                 0.73000 \n      b[(Intercept) artist:Atlas_Genius] \n                                 0.71450 \n          b[(Intercept) artist:Jazzinuf] \n                                 0.62125 \n             b[(Intercept) artist:Elisa] \n                                 0.79210 \n     b[(Intercept) artist:House_Of_Pain] \n                                 0.67505 \nb[(Intercept) artist:Black_Stone_Cherry] \n                                 0.63080 \n             b[(Intercept) artist:C-Kan] \n                                 0.71395 \n         b[(Intercept) artist:Zeds_Dead] \n                                 0.69215 \n    b[(Intercept) artist:David_Lee_Roth] \n                                 0.74245 \n              b[(Intercept) artist:NODE] \n                                 0.66665 \n  b[(Intercept) artist:Michael_Kiwanuka] \n                                 0.78820 \n        b[(Intercept) artist:The_Wrecks] \n                                 0.88410 \n            b[(Intercept) artist:The_xx] \n                                 0.54305 \n           b[(Intercept) artist:Placebo] \n                                 0.63240 \n b[(Intercept) artist:Mike_WiLL_Made-It] \n                                 0.51755 \n    b[(Intercept) artist:Kendrick_Lamar] \n                                 0.27000 \n     b[(Intercept) artist:X_Ambassadors] \n                                 0.55395 \n            b[(Intercept) artist:Hinder] \n                                 0.57840 \n             b[(Intercept) artist:Au/Ra] \n                                 0.66580 \n     b[(Intercept) artist:Missy_Elliott] \n                                 0.67095 \n         b[(Intercept) artist:The_Blaze] \n                                 0.76140 \n   b[(Intercept) artist:Vampire_Weekend] \n                                 0.57625 \n              b[(Intercept) artist:Alok] \n                                 0.34775 \n     b[(Intercept) artist:León_Larregui] \n                                 0.84135 \n    b[(Intercept) artist:Sufjan_Stevens] \n                                 0.79540 \n           b[(Intercept) artist:Beyoncé] \n                                 0.29155 \n       b[(Intercept) artist:Frank_Ocean] \n                                 0.23715 \n     b[(Intercept) artist:Sean_Kingston] \n                                 0.94175 \n           b[(Intercept) artist:J._Cole] \n                                 0.43655 \n    b[(Intercept) artist:Camila_Cabello] \n                                 0.24760 \n         b[(Intercept) artist:Lil_Skies] \n                                 0.83165 \n            b[(Intercept) artist:Camilo] \n                                 0.51365 \n                                   sigma \n                                 0.87310 \n   Sigma[artist:(Intercept),(Intercept)] \n                                 0.20830 \n```\n:::\n\n```{.r .cell-code}\nrhat(spotify_hierarchical)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                             (Intercept) \n                               1.0023373 \n             b[(Intercept) artist:Mia_X] \n                               0.9999563 \n     b[(Intercept) artist:Chris_Goldarg] \n                               1.0002134 \n         b[(Intercept) artist:Soul&Roll] \n                               1.0000290 \n        b[(Intercept) artist:Honeywagon] \n                               1.0001784 \n          b[(Intercept) artist:Röyksopp] \n                               1.0000845 \n         b[(Intercept) artist:Freestyle] \n                               1.0000007 \n          b[(Intercept) artist:DA_Image] \n                               0.9999542 \n         b[(Intercept) artist:Jean_Juan] \n                               1.0002437 \n          b[(Intercept) artist:TV_Noise] \n                               1.0006862 \n         b[(Intercept) artist:Kid_Frost] \n                               1.0003440 \n     b[(Intercept) artist:Tamar_Braxton] \n                               1.0001073 \n             b[(Intercept) artist:BUNT.] \n                               1.0001658 \n               b[(Intercept) artist:MTK] \n                               1.0002301 \n      b[(Intercept) artist:Atlas_Genius] \n                               1.0000350 \n          b[(Intercept) artist:Jazzinuf] \n                               1.0000551 \n             b[(Intercept) artist:Elisa] \n                               1.0002368 \n     b[(Intercept) artist:House_Of_Pain] \n                               1.0000201 \nb[(Intercept) artist:Black_Stone_Cherry] \n                               1.0003101 \n             b[(Intercept) artist:C-Kan] \n                               1.0002560 \n         b[(Intercept) artist:Zeds_Dead] \n                               1.0002598 \n    b[(Intercept) artist:David_Lee_Roth] \n                               1.0004112 \n              b[(Intercept) artist:NODE] \n                               1.0006272 \n  b[(Intercept) artist:Michael_Kiwanuka] \n                               1.0000876 \n        b[(Intercept) artist:The_Wrecks] \n                               1.0002219 \n            b[(Intercept) artist:The_xx] \n                               1.0003746 \n           b[(Intercept) artist:Placebo] \n                               1.0003957 \n b[(Intercept) artist:Mike_WiLL_Made-It] \n                               1.0002158 \n    b[(Intercept) artist:Kendrick_Lamar] \n                               1.0012166 \n     b[(Intercept) artist:X_Ambassadors] \n                               1.0005121 \n            b[(Intercept) artist:Hinder] \n                               1.0004480 \n             b[(Intercept) artist:Au/Ra] \n                               1.0005041 \n     b[(Intercept) artist:Missy_Elliott] \n                               1.0005359 \n         b[(Intercept) artist:The_Blaze] \n                               1.0002700 \n   b[(Intercept) artist:Vampire_Weekend] \n                               1.0006466 \n              b[(Intercept) artist:Alok] \n                               1.0005930 \n     b[(Intercept) artist:León_Larregui] \n                               1.0002143 \n    b[(Intercept) artist:Sufjan_Stevens] \n                               1.0003860 \n           b[(Intercept) artist:Beyoncé] \n                               1.0012719 \n       b[(Intercept) artist:Frank_Ocean] \n                               1.0012760 \n     b[(Intercept) artist:Sean_Kingston] \n                               1.0001884 \n           b[(Intercept) artist:J._Cole] \n                               1.0007679 \n    b[(Intercept) artist:Camila_Cabello] \n                               1.0016487 \n         b[(Intercept) artist:Lil_Skies] \n                               1.0001676 \n            b[(Intercept) artist:Camilo] \n                               1.0005877 \n                                   sigma \n                               1.0001041 \n   Sigma[artist:(Intercept),(Intercept)] \n                               1.0009705 \n```\n:::\n\n```{.r .cell-code}\npp_check(spotify_hierarchical) + \n  xlab(\"popularity\")\n```\n\n::: {.cell-output-display}\n![](16_notes_files/figure-html/unnamed-chunk-5-4.png){width=672}\n:::\n\n```{.r .cell-code}\n# Store the simulation in a data frame\nspotify_hierarchical_df <- as.data.frame(spotify_hierarchical)\n\n# Check out the first 3 and last 3 parameter labels\nspotify_hierarchical_df %>% \n  colnames() %>% \n  as.data.frame() %>% \n  slice(1:3, 45:47)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                                      .\n1                           (Intercept)\n2           b[(Intercept) artist:Mia_X]\n3   b[(Intercept) artist:Chris_Goldarg]\n4          b[(Intercept) artist:Camilo]\n5                                 sigma\n6 Sigma[artist:(Intercept),(Intercept)]\n```\n:::\n:::\n\n\n## 16.4.2 Posterior analysis of global parameters\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntidy(spotify_hierarchical, effects = \"fixed\", \n     conf.int = TRUE, conf.level = 0.80)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 × 5\n  term        estimate std.error conf.low conf.high\n  <chr>          <dbl>     <dbl>    <dbl>     <dbl>\n1 (Intercept)     52.4      2.41     49.3      55.5\n```\n:::\n\n```{.r .cell-code}\ntidy(spotify_hierarchical, effects = \"ran_pars\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2 × 3\n  term                    group    estimate\n  <chr>                   <chr>       <dbl>\n1 sd_(Intercept).artist   artist       15.2\n2 sd_Observation.Residual Residual     14.0\n```\n:::\n\n```{.r .cell-code}\n15.1^2 / (15.1^2 + 14.0^2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.5377468\n```\n:::\n\n```{.r .cell-code}\n14.0^2 / (15.1^2 + 14.0^2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.4622532\n```\n:::\n:::\n\n\n## 16.4.3 Posterior analysis of group-specific parameters\n\n\n::: {.cell}\n\n```{.r .cell-code}\nartist_summary <- tidy(spotify_hierarchical, effects = \"ran_vals\", \n                       conf.int = TRUE, conf.level = 0.80)\n\n# Check out the results for the first & last 2 artists\nartist_summary %>% \n  select(level, conf.low, conf.high) %>% \n  slice(1:2, 43:44)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 4 × 3\n  level         conf.low conf.high\n  <chr>            <dbl>     <dbl>\n1 Mia_X            -40.6     -23.1\n2 Chris_Goldarg    -39.2     -26.9\n3 Lil_Skies         11.1      30.4\n4 Camilo            19.5      32.5\n```\n:::\n\n```{.r .cell-code}\n# Get MCMC chains for each mu_j\nartist_chains <- spotify_hierarchical %>%\n  spread_draws(`(Intercept)`, b[,artist]) %>% \n  mutate(mu_j = `(Intercept)` + b) \n\n# Check it out\nartist_chains %>% \n  select(artist, `(Intercept)`, b, mu_j) %>% \n  head(4)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 4 × 4\n# Groups:   artist [4]\n  artist              `(Intercept)`     b  mu_j\n  <chr>                       <dbl> <dbl> <dbl>\n1 artist:Alok                  55.9  10.9  66.8\n2 artist:Atlas_Genius          55.9 -17.5  38.4\n3 artist:Au/Ra                 55.9  11.7  67.6\n4 artist:Beyoncé               55.9  16.5  72.4\n```\n:::\n\n```{.r .cell-code}\n# Get posterior summaries for mu_j\nartist_summary_scaled <- artist_chains %>% \n  select(-`(Intercept)`, -b) %>% \n  mean_qi(.width = 0.80) %>% \n  mutate(artist = fct_reorder(artist, mu_j))\n\n# Check out the results\nartist_summary_scaled %>% \n  select(artist, mu_j, .lower, .upper) %>% \n  head(4)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 4 × 4\n  artist               mu_j .lower .upper\n  <fct>               <dbl>  <dbl>  <dbl>\n1 artist:Alok          64.3   60.3   68.2\n2 artist:Atlas_Genius  47.0   38.8   55.1\n3 artist:Au/Ra         59.5   52.1   67.0\n4 artist:BUNT.         44.7   35.5   53.7\n```\n:::\n\n```{.r .cell-code}\nggplot(artist_summary_scaled, \n       aes(x = artist, y = mu_j, ymin = .lower, ymax = .upper)) +\n  geom_pointrange() +\n  xaxis_text(angle = 90, hjust = 1)\n```\n\n::: {.cell-output-display}\n![](16_notes_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n\n```{.r .cell-code}\nartist_means %>% \n  filter(artist %in% c(\"Frank Ocean\", \"Lil Skies\"))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2 × 3\n  artist      count popularity\n  <fct>       <int>      <dbl>\n1 Frank Ocean    40       69.8\n2 Lil Skies       3       79.3\n```\n:::\n:::\n\n\n# 16.5 Posterior prediction\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Simulate Ocean's posterior predictive model\nset.seed(84735)\nocean_chains <- spotify_hierarchical_df %>%\n  rename(b = `b[(Intercept) artist:Frank_Ocean]`) %>% \n  select(`(Intercept)`, b, sigma) %>% \n  mutate(mu_ocean = `(Intercept)` + b,\n         y_ocean = rnorm(20000, mean = mu_ocean, sd = sigma))\n\n# Check it out\nhead(ocean_chains, 3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  (Intercept)        b    sigma mu_ocean  y_ocean\n1    55.88832 13.56070 13.10217 69.44902 78.19121\n2    52.45597 16.05214 13.70283 68.50811 66.81115\n3    53.23302 15.90873 14.86667 69.14175 80.75065\n```\n:::\n\n```{.r .cell-code}\n# Posterior summary of Y_new,j\nocean_chains %>% \n  mean_qi(y_ocean, .width = 0.80)    \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 × 6\n  y_ocean .lower .upper .width .point .interval\n    <dbl>  <dbl>  <dbl>  <dbl> <chr>  <chr>    \n1    69.4   51.3   87.5    0.8 mean   qi       \n```\n:::\n\n```{.r .cell-code}\n# Posterior summary of mu_j\nartist_summary_scaled %>% \n  filter(artist == \"artist:Frank_Ocean\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 × 7\n  artist              mu_j .lower .upper .width .point .interval\n  <fct>              <dbl>  <dbl>  <dbl>  <dbl> <chr>  <chr>    \n1 artist:Frank_Ocean  69.4   66.5   72.2    0.8 mean   qi       \n```\n:::\n\n```{.r .cell-code}\nset.seed(84735)\nmohsen_chains <- spotify_hierarchical_df %>%\n  mutate(sigma_mu = sqrt(`Sigma[artist:(Intercept),(Intercept)]`),\n         mu_mohsen = rnorm(20000, `(Intercept)`, sigma_mu),\n         y_mohsen = rnorm(20000, mu_mohsen, sigma))\n\n# Posterior predictive summaries\nmohsen_chains %>% \n  mean_qi(y_mohsen, .width = 0.80)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 × 6\n  y_mohsen .lower .upper .width .point .interval\n     <dbl>  <dbl>  <dbl>  <dbl> <chr>  <chr>    \n1     52.2   25.6   78.6    0.8 mean   qi       \n```\n:::\n\n```{.r .cell-code}\nset.seed(84735)\nprediction_shortcut <- posterior_predict(\n  spotify_hierarchical,\n  newdata = data.frame(artist = c(\"Frank Ocean\", \"Mohsen Beats\")))\n\n# Posterior predictive model plots\nmcmc_areas(prediction_shortcut, prob = 0.8) +\n  ggplot2::scale_y_discrete(labels = c(\"Frank Ocean\", \"Mohsen Beats\"))\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nScale for y is already present.\nAdding another scale for y, which will replace the existing scale.\n```\n:::\n\n::: {.cell-output-display}\n![](16_notes_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n:::\n\n\n# 16.6 Shrinkage & the bias-variance trade-off\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(84735)\npredictions_hierarchical <- posterior_predict(spotify_hierarchical, \n                                              newdata = artist_means)\n\n# Posterior predictive plots\nppc_intervals(artist_means$popularity, yrep = predictions_hierarchical, \n              prob_outer = 0.80) +\n  ggplot2::scale_x_continuous(labels = artist_means$artist, \n                              breaks = 1:nrow(artist_means)) +\n  xaxis_text(angle = 90, hjust = 1) + \n  geom_hline(yintercept = 58.4, linetype = \"dashed\")\n```\n\n::: {.cell-output-display}\n![](16_notes_files/figure-html/unnamed-chunk-9-1.png){width=672}\n:::\n\n```{.r .cell-code}\nartist_means %>% \n  filter(artist %in% c(\"Camila Cabello\", \"Lil Skies\"))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2 × 3\n  artist         count popularity\n  <fct>          <int>      <dbl>\n1 Camila Cabello    38       77.1\n2 Lil Skies          3       79.3\n```\n:::\n:::\n\n\n# 16.7 Not everything is hierarchical\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata(bikes)\nbikes %>% \n  select(rides, weekend) %>% \n  head(3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  rides weekend\n1   654    TRUE\n2  1229   FALSE\n3  1454   FALSE\n```\n:::\n\n```{.r .cell-code}\nbikes %>%\n  group_by(weekend) %>% \n  tally()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2 × 2\n  weekend     n\n  <lgl>   <int>\n1 FALSE     359\n2 TRUE      141\n```\n:::\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}