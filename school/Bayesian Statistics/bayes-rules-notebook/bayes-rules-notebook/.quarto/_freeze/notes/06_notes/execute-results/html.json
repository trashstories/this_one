{
  "hash": "a52584ab979bd1fa4e486284ef9b4de4",
  "result": {
    "markdown": "---\ntitle: \"6: Approximating the Posterior\"\neditor_options: \n  chunk_output_type: console\n---\n\n::: {.cell}\n\n```{.r .cell-code}\nknitr::opts_chunk$set(eval = FALSE)\n\n# Load packages\nlibrary(tidyverse)\nlibrary(janitor)\nlibrary(rstan)\nlibrary(bayesplot)\nlibrary(bayesrules)\n```\n:::\n\n\n# 6.1.1 A Beta-Binomial example\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Step 1: Define a grid of 6 pi values\ngrid_data <- data.frame(pi_grid = seq(from = 0, to = 1, length = 6))\n\n# Step 2: Evaluate the prior & likelihood at each pi\ngrid_data <- grid_data %>% \n  mutate(prior = dbeta(pi_grid, 2, 2),\n         likelihood = dbinom(9, 10, pi_grid))\n\n# Step 3: Approximate the posterior\ngrid_data <- grid_data %>% \n  mutate(unnormalized = likelihood * prior,\n         posterior = unnormalized / sum(unnormalized))\n\n# Confirm that the posterior approximation sums to 1\ngrid_data %>% \n  summarize(sum(unnormalized), sum(posterior))\n  sum(unnormalized) sum(posterior)\n  \n# Examine the grid approximated posterior\nround(grid_data, 2)\n\n# Plot the grid approximated posterior\nggplot(grid_data, aes(x = pi_grid, y = posterior)) + \n  geom_point() + \n  geom_segment(aes(x = pi_grid, xend = pi_grid, y = 0, yend = posterior))\n\n# Set the seed\nset.seed(84735)\n\n# Step 4: sample from the discretized posterior\npost_sample <- sample_n(grid_data, size = 10000, \n                        weight = posterior, replace = TRUE)\n\n# A table of the 10000 sample values\npost_sample %>% \n  tabyl(pi_grid) %>% \n  adorn_totals(\"row\")\n\n# Histogram of the grid simulation with posterior pdf\nggplot(post_sample, aes(x = pi_grid)) + \n  geom_histogram(aes(y = ..density..), color = \"white\") + \n  stat_function(fun = dbeta, args = list(11, 3)) + \n  lims(x = c(0, 1))\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Step 1: Define a grid of 101 pi values\ngrid_data  <- data.frame(pi_grid = seq(from = 0, to = 1, length = 101))\n\n# Step 2: Evaluate the prior & likelihood at each pi\ngrid_data <- grid_data %>% \n  mutate(prior = dbeta(pi_grid, 2, 2),\n         likelihood = dbinom(9, 10, pi_grid))\n\n\n# Step 3: Approximate the posterior\ngrid_data <- grid_data %>% \n  mutate(unnormalized = likelihood * prior,\n         posterior = unnormalized / sum(unnormalized))\n\nggplot(grid_data, aes(x = pi_grid, y = posterior)) + \n  geom_point() + \n  geom_segment(aes(x = pi_grid, xend = pi_grid, y = 0, yend = posterior))\n\n# Set the seed\nset.seed(84735)\n\n# Step 4: sample from the discretized posterior\npost_sample <- sample_n(grid_data, size = 10000, \n                        weight = posterior, replace = TRUE)\n\nggplot(post_sample, aes(x = pi_grid)) + \n  geom_histogram(aes(y = ..density..), color = \"white\", binwidth = 0.05) + \n  stat_function(fun = dbeta, args = list(11, 3)) + \n  lims(x = c(0, 1))\n```\n:::\n\n\n# 6.1.2 A Gamma-Poisson example\n\nFill in the code below to construct a grid approximation of the Gamma-Poisson posterior corresponding to (6.2). In doing so, use a grid of 501 $\\lambda$ values between 0 and 15.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot_gamma_poisson(s = 3, r = 1, sum_y = 10, n = 2, posterior = FALSE)\n\n# Step 1: Define a grid of 501 lambda values\ngrid_data   <- data.frame(\n  lambda_grid = seq(from = 0, to = 15, length = 501))\n\n# Step 2: Evaluate the prior & likelihood at each lambda\ngrid_data <- grid_data %>% \n  mutate(prior = dgamma(lambda_grid, 3, 1),\n         likelihood = dpois(2, lambda_grid) * dpois(8, lambda_grid))\n\n# Step 3: Approximate the posterior\ngrid_data <- grid_data %>% \n  mutate(unnormalized = likelihood * prior,\n         posterior = unnormalized / sum(unnormalized))\n\n# Set the seed\nset.seed(84735)\n\n# Step 4: sample from the discretized posterior\npost_sample <- sample_n(grid_data, size = 10000, \n                        weight = posterior, replace = TRUE)\n\n# Histogram of the grid simulation with posterior pdf \nggplot(post_sample, aes(x = lambda_grid)) + \n  geom_histogram(aes(y = ..density..), color = \"white\") + \n  stat_function(fun = dgamma, args = list(13, 3)) + \n  lims(x = c(0, 15))\n```\n:::\n\n\n# 6.2.1 A Beta-Binomial example\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# STEP 1: DEFINE the model\nbb_model <- \"\n  data {\n    int<lower = 0, upper = 10> Y;\n  }\n  parameters {\n    real<lower = 0, upper = 1> pi;\n  }\n  model {\n    Y ~ binomial(10, pi);\n    pi ~ beta(2, 2);\n  }\n\"\n\n# STEP 2: SIMULATE the posterior\nbb_sim <- stan(model_code = bb_model, data = list(Y = 9), \n               chains = 4, iter = 5000*2, seed = 84735)\n\nas.array(bb_sim, pars = \"pi\") %>% \n  head(4)\n\nmcmc_trace(bb_sim, pars = \"pi\", size = 0.1)\n\n# Histogram of the Markov chain values\nmcmc_hist(bb_sim, pars = \"pi\") + \n  yaxis_text(TRUE) + \n  ylab(\"count\")\n\n# Density plot of the Markov chain values\nmcmc_dens(bb_sim, pars = \"pi\") + \n  yaxis_text(TRUE) + \n  ylab(\"density\")\n```\n:::\n\n\n# 6.2.2 A Gamma-Poisson example\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# STEP 1: DEFINE the model\ngp_model <- \"\n  data {\n    int<lower = 0> Y[2];\n  }\n  parameters {\n    real<lower = 0> lambda;\n  }\n  model {\n    Y ~ poisson(lambda);\n    lambda ~ gamma(3, 1);\n  }\n\"\n\n# STEP 2: SIMULATE the posterior\ngp_sim <- stan(model_code = gp_model, data = list(Y = c(2,8)), \n              chains = 4, iter = 5000*2, seed = 84735)\n\n# Trace plots of the 4 Markov chains\nmcmc_trace(gp_sim, pars = \"lambda\", size = 0.1)\n\n# Histogram of the Markov chain values\nmcmc_hist(gp_sim, pars = \"lambda\") + \n  yaxis_text(TRUE) + \n  ylab(\"count\")\n\n# Density plot of the Markov chain values\nmcmc_dens(gp_sim, pars = \"lambda\") + \n  yaxis_text(TRUE) + \n  ylab(\"density\")\n```\n:::\n\n\n# 6.3.2 Comparing parallel chains\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Density plots of individual chains\nmcmc_dens_overlay(bb_sim, pars = \"pi\") + \n  ylab(\"density\")\n\n# STEP 2: SIMULATE the posterior\nbb_sim_short <- stan(model_code = bb_model, data = list(Y = 9), \n                     chains = 4, iter = 50*2, seed = 84735)\n\n# Trace plots of short chains\nmcmc_trace(bb_sim_short, pars = \"pi\")\n\n# Density plots of individual short chains\nmcmc_dens_overlay(bb_sim_short, pars = \"pi\")\n```\n:::\n\n\n# 6.3.3 Calculating effective sample size & autocorrelation\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Calculate the effective sample size ratio\nneff_ratio(bb_sim, pars = c(\"pi\"))\n\nmcmc_trace(bb_sim, pars = \"pi\")\nmcmc_acf(bb_sim, pars = \"pi\")\n\n# Simulate a thinned MCMC sample\nthinned_sim <- stan(model_code = bb_model, data = list(Y = 9), \n                    chains = 4, iter = 5000*2, seed = 84735, thin = 10)\n\n# Check out the results\nmcmc_trace(thinned_sim, pars = \"pi\")\nmcmc_acf(thinned_sim, pars = \"pi\")\n```\n:::\n\n\n# 6.3.4 Calculating R-hat\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrhat(bb_sim, pars = \"pi\")\n```\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}