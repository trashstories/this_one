{
  "hash": "a95f84385896b06ffe2f0b125fc47431",
  "result": {
    "markdown": "---\ntitle: \"15: Hierarchical Models are Exciting\"\neditor_options: \n  chunk_output_type: console\n---\n\n::: {.cell}\n\n```{.r .cell-code}\n# Load packages\nlibrary(bayesrules)\nlibrary(tidyverse)\nlibrary(rstanarm)\nlibrary(broom.mixed)\nlibrary(lme4)\n\ncolors <- c( \"#7400CC\", \"#CC0AA4\", \"#0E0ACC\", \"#3ACC14\", \"#CCAC14\")\n```\n:::\n\n\n\n# 15.6.1 Conceptual exercises\n\n## Exercise 15.1 (Three pooling types: explain to your friend) \n\nIn one to two sentences each, explain the following concepts to your friend Hakeem, who has taken an intro statistics course but otherwise is new to pooled data.\n\na. Complete pooling\n   - **All observations are analyzed together in one group**\nb. No pooling\n   - **Each individually identified type of record (group) is analyzed on its own (i.e. one person, one lab, one tract, etc)**\nc. Partial pooling\n   - **Groups are analyzed separately but use information about the entire sample to inform predictions**\n\n## Exercise 15.2 (Three pooling types: redux) \n\nHakeem now understands the three pooling approaches thanks to your excellent explanations in the previous exercise. Now he has some follow-up questions! Answer these in your own words and using your own examples.\n\na. Can you give me an example when we might want to use the partial pooling approach?\n   - **When there are multiple records tied to the same entity**\nb. Why wouldn’t we always just use the complete pooling approach? It seems easier!\n   - **Complete pooling might miss trends within groups that provide more basis for accurate predictions**\nc. Does the no pooled approach have any drawbacks? It seems that there are fewer assumptions.\n   - **No pooled ignores information about the other groups which could lead to misinterpreted finding that only apply to specific groups**\nd. Can you remind me what the difference is between within-group variability and between-group variability? And how does that relate to partial pooling?\n   - **within-group - degree of the variability among multiple observations within each group**\n   - **between-group - variability from group to group**\n\n# 15.6.2 Applied exercises\n\nInterested in the impact of sleep deprivation on reaction time, Belenky et al. (2003) enlisted 18 subjects in a study. The subjects got a regular night’s sleep on “day 0” of the study, and were then restricted to 3 hours of sleep per night for the next 9 days. Each day, researchers recorded the subjects’ reaction times (in ms) on a series of tests. The results are provided in the `sleepstudy` dataset in the *lme4* package.\n\n## Exercise 15.3 (Hierarchical data) \n\nThe `sleepstudy` data is hierarchical. Draw a diagram in the spirit of Figure 15.8 that captures the hierarchical framework. Think: What are the “groups?”\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsleep <- sleepstudy\n```\n:::\n\n\n   - Records -> **Subject** -> Days \n\n## Exercise 15.4 (Complete pooling: Part I) \n\nSuppose that we (incorrectly) took a complete pooling approach to modeling `Reaction` time ($Y$) by `Days` of sleep deprivation ($X$).\n\na. To explore the complete pooled behavior of the data points, construct and discuss a plot of `Reaction` by `Days`. In doing so, ignore the subjects and include the observed trend in the relationship.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsleep %>% \n  ggplot(aes(Days, Reaction)) +\n  geom_smooth(method = \"lm\", se = FALSE) +\n  geom_point(aes(color = Subject)) + \n  theme_light()\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n`geom_smooth()` using formula = 'y ~ x'\n```\n:::\n\n::: {.cell-output-display}\n![](15_exercises_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n:::\n\n\nb. Draw a diagram in the spirit of Figure 15.8 that captures the complete pooling framework.\n   - Records -> Days\n   \nc. Using careful notation, write out the structure for the complete pooled model of $Y$ by $X$.\n\n\\begin{equation}\nY_i | \\beta_0, \\beta_1, \\sigma \\stackrel{ind}{\\sim} N\\left(\\mu_i, \\sigma^2\\right) \\;\\; \\text{ with } \\;\\; \\mu_i = \\beta_0 + \\beta_1X_i\n\\end{equation}\n\n\n::: {.cell hash='15_exercises_cache/html/unnamed-chunk-4_4e42f655640bddef461482980afe0268'}\n\n```{.r .cell-code}\ncomplete_pooled_model <- stan_glm(\n  Reaction ~ Days, \n  data = sleep, family = gaussian, \n  prior_intercept = normal(0, 2.5, autoscale = TRUE),\n  prior = normal(0, 2.5, autoscale = TRUE), \n  prior_aux = exponential(1, autoscale = TRUE),\n  chains = 4, iter = 5000*2, seed = 84735)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nSAMPLING FOR MODEL 'continuous' NOW (CHAIN 1).\nChain 1: \nChain 1: Gradient evaluation took 4.1e-05 seconds\nChain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.41 seconds.\nChain 1: Adjust your expectations accordingly!\nChain 1: \nChain 1: \nChain 1: Iteration:    1 / 10000 [  0%]  (Warmup)\nChain 1: Iteration: 1000 / 10000 [ 10%]  (Warmup)\nChain 1: Iteration: 2000 / 10000 [ 20%]  (Warmup)\nChain 1: Iteration: 3000 / 10000 [ 30%]  (Warmup)\nChain 1: Iteration: 4000 / 10000 [ 40%]  (Warmup)\nChain 1: Iteration: 5000 / 10000 [ 50%]  (Warmup)\nChain 1: Iteration: 5001 / 10000 [ 50%]  (Sampling)\nChain 1: Iteration: 6000 / 10000 [ 60%]  (Sampling)\nChain 1: Iteration: 7000 / 10000 [ 70%]  (Sampling)\nChain 1: Iteration: 8000 / 10000 [ 80%]  (Sampling)\nChain 1: Iteration: 9000 / 10000 [ 90%]  (Sampling)\nChain 1: Iteration: 10000 / 10000 [100%]  (Sampling)\nChain 1: \nChain 1:  Elapsed Time: 0.143 seconds (Warm-up)\nChain 1:                0.184 seconds (Sampling)\nChain 1:                0.327 seconds (Total)\nChain 1: \n\nSAMPLING FOR MODEL 'continuous' NOW (CHAIN 2).\nChain 2: \nChain 2: Gradient evaluation took 7e-06 seconds\nChain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.07 seconds.\nChain 2: Adjust your expectations accordingly!\nChain 2: \nChain 2: \nChain 2: Iteration:    1 / 10000 [  0%]  (Warmup)\nChain 2: Iteration: 1000 / 10000 [ 10%]  (Warmup)\nChain 2: Iteration: 2000 / 10000 [ 20%]  (Warmup)\nChain 2: Iteration: 3000 / 10000 [ 30%]  (Warmup)\nChain 2: Iteration: 4000 / 10000 [ 40%]  (Warmup)\nChain 2: Iteration: 5000 / 10000 [ 50%]  (Warmup)\nChain 2: Iteration: 5001 / 10000 [ 50%]  (Sampling)\nChain 2: Iteration: 6000 / 10000 [ 60%]  (Sampling)\nChain 2: Iteration: 7000 / 10000 [ 70%]  (Sampling)\nChain 2: Iteration: 8000 / 10000 [ 80%]  (Sampling)\nChain 2: Iteration: 9000 / 10000 [ 90%]  (Sampling)\nChain 2: Iteration: 10000 / 10000 [100%]  (Sampling)\nChain 2: \nChain 2:  Elapsed Time: 0.145 seconds (Warm-up)\nChain 2:                0.205 seconds (Sampling)\nChain 2:                0.35 seconds (Total)\nChain 2: \n\nSAMPLING FOR MODEL 'continuous' NOW (CHAIN 3).\nChain 3: \nChain 3: Gradient evaluation took 9e-06 seconds\nChain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.09 seconds.\nChain 3: Adjust your expectations accordingly!\nChain 3: \nChain 3: \nChain 3: Iteration:    1 / 10000 [  0%]  (Warmup)\nChain 3: Iteration: 1000 / 10000 [ 10%]  (Warmup)\nChain 3: Iteration: 2000 / 10000 [ 20%]  (Warmup)\nChain 3: Iteration: 3000 / 10000 [ 30%]  (Warmup)\nChain 3: Iteration: 4000 / 10000 [ 40%]  (Warmup)\nChain 3: Iteration: 5000 / 10000 [ 50%]  (Warmup)\nChain 3: Iteration: 5001 / 10000 [ 50%]  (Sampling)\nChain 3: Iteration: 6000 / 10000 [ 60%]  (Sampling)\nChain 3: Iteration: 7000 / 10000 [ 70%]  (Sampling)\nChain 3: Iteration: 8000 / 10000 [ 80%]  (Sampling)\nChain 3: Iteration: 9000 / 10000 [ 90%]  (Sampling)\nChain 3: Iteration: 10000 / 10000 [100%]  (Sampling)\nChain 3: \nChain 3:  Elapsed Time: 0.161 seconds (Warm-up)\nChain 3:                0.197 seconds (Sampling)\nChain 3:                0.358 seconds (Total)\nChain 3: \n\nSAMPLING FOR MODEL 'continuous' NOW (CHAIN 4).\nChain 4: \nChain 4: Gradient evaluation took 6e-06 seconds\nChain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.06 seconds.\nChain 4: Adjust your expectations accordingly!\nChain 4: \nChain 4: \nChain 4: Iteration:    1 / 10000 [  0%]  (Warmup)\nChain 4: Iteration: 1000 / 10000 [ 10%]  (Warmup)\nChain 4: Iteration: 2000 / 10000 [ 20%]  (Warmup)\nChain 4: Iteration: 3000 / 10000 [ 30%]  (Warmup)\nChain 4: Iteration: 4000 / 10000 [ 40%]  (Warmup)\nChain 4: Iteration: 5000 / 10000 [ 50%]  (Warmup)\nChain 4: Iteration: 5001 / 10000 [ 50%]  (Sampling)\nChain 4: Iteration: 6000 / 10000 [ 60%]  (Sampling)\nChain 4: Iteration: 7000 / 10000 [ 70%]  (Sampling)\nChain 4: Iteration: 8000 / 10000 [ 80%]  (Sampling)\nChain 4: Iteration: 9000 / 10000 [ 90%]  (Sampling)\nChain 4: Iteration: 10000 / 10000 [100%]  (Sampling)\nChain 4: \nChain 4:  Elapsed Time: 0.135 seconds (Warm-up)\nChain 4:                0.19 seconds (Sampling)\nChain 4:                0.325 seconds (Total)\nChain 4: \n```\n:::\n\n```{.r .cell-code}\n# Posterior summary statistics\ntidy(complete_pooled_model, conf.int = TRUE, conf.level = 0.80)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2 × 5\n  term        estimate std.error conf.low conf.high\n  <chr>          <dbl>     <dbl>    <dbl>     <dbl>\n1 (Intercept)    251.       6.63   243.       260. \n2 Days            10.4      1.24     8.88      12.1\n```\n:::\n\n```{.r .cell-code}\n# Plot of the posterior median model\nsleep %>% \n  ggplot(aes(Days, Reaction, group = Subject)) + \n  geom_smooth(method = \"lm\", se = FALSE, color = \"#FF99F9\", size = 0.5) + \n  geom_abline(aes(intercept = 251, slope = 10.4), color = \"#7400CC\", linewidth = 1) + \n  theme_light()\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n`geom_smooth()` using formula = 'y ~ x'\n```\n:::\n\n::: {.cell-output-display}\n![](15_exercises_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n:::\n\n\n## Exercise 15.5 (Complete pooling: Part II) \n\nIn the context of the sleep study, what two incorrect assumptions does the complete pooled model make and why are these inappropriate in the sleep study analysis?\n\n   - **That the reaction time will change consistently or similarly for all subjects.**\n\n## Exercise 15.6 (No pooling: Part I) \n\nSuppose instead that we (incorrectly) took a no pooling approach in our sleep study analysis.\n\na. To explore the no pooled behavior of the data points, construct and discuss separate scatterplots of `Reaction` by `Days` for each `Subject`, including subject-specific trend lines.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsleep %>% \n  ggplot(aes(Days, Reaction, color = Subject)) +\n  geom_smooth(method = \"lm\", se = FALSE) +\n  geom_point() + \n  theme_light()\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n`geom_smooth()` using formula = 'y ~ x'\n```\n:::\n\n::: {.cell-output-display}\n![](15_exercises_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n:::\n\n\nb. Draw a diagram in the spirit of Figure 15.6 that captures the no pooling framework.\n   - Subject -> Days\n   \nc. Using careful notation, write out the structure for the no pooled model of $Y$ by $X$.\n\n\\begin{equation}\nY_{ij} | \\beta_{0j}, \\beta_{1j}, \\sigma \\sim N\\left(\\mu_{ij}, \\sigma^2\\right) \\;\\; \\text{ with } \\;\\; \\mu_{ij} = \\beta_{0j} + \\beta_{1j} X_{ij}\n\\end{equation}\n\n## Exercise 15.7 (No pooling: Part II) \n\nIn the context of the sleep study, what are the two main drawbacks to analyzing the relationship between reaction time and sleep deprivation using a no pooling approach?\n\n   - **Complete pooling does not consider the variance among subjects, and no pooling ignores the context of the other subjects.**\n\n## Exercise 15.8 (Complete vs no vs partial pooling) \n\nSuppose we only had data on the two subjects below. For both, provide a loose sketch of three separate trend lines corresponding to a complete pooled, no pooled, and partial pooled model of `Reaction` time by `Days`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsleep %>% \n  filter(Subject %in% c(\"308\", \"335\")) %>% \n  ggplot(aes(Days, Reaction)) +\n  geom_smooth(aes(color = Subject), method = \"lm\", se = FALSE, linewidth = 1.2) +\n  geom_abline(aes(intercept = 251, slope = 10.4), color = \"black\", linewidth = 1) + \n  geom_point(aes(color = Subject), size = 3) + \n  facet_wrap(~ Subject) +\n  scale_color_manual(values = colors) +\n  theme_light()\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n`geom_smooth()` using formula = 'y ~ x'\n```\n:::\n\n::: {.cell-output-display}\n![](15_exercises_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}